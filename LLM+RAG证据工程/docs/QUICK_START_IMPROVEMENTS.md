# LLM+RAGè¯æ®å·¥ç¨‹ å·¥ä¸šåŒ–æ”¹è¿›ï¼šå¿«é€Ÿå¯åŠ¨æŒ‡å—

**ç›®æ ‡**ï¼š6å‘¨å†…ä»ç§‘ç ”ä»£ç ï¼ˆ3.0/5.0ï¼‰å‡çº§è‡³å·¥ä¸šçº§ï¼ˆ4.0/5.0ï¼‰

---

## ğŸš€ ç¬¬1å‘¨ï¼šåŸºç¡€è®¾æ–½å»ºç«‹

### Day 1-2ï¼šæ—¥å¿—ç³»ç»Ÿè¿ç§»

**åˆ›å»º `src/logger.py`**ï¼š

```python
"""ç»Ÿä¸€æ—¥å¿—é…ç½®"""
import logging
import logging.handlers
from pathlib import Path

def setup_logger(name: str, log_file: str = "dr_pipeline.log", level: str = "INFO"):
    """é…ç½®æ ‡å‡†logger"""
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level.upper()))

    # é¿å…é‡å¤handler
    if logger.handlers:
        return logger

    # æ–‡ä»¶handlerï¼ˆå¸¦è½®æ¢ï¼‰
    log_path = Path(log_file)
    log_path.parent.mkdir(parents=True, exist_ok=True)
    file_handler = logging.handlers.RotatingFileHandler(
        log_path,
        maxBytes=100*1024*1024,  # 100MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    # æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s | %(name)s | %(levelname)s | %(funcName)s:%(lineno)d | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger
```

**è¿ç§»ç¤ºä¾‹**ï¼ˆstep6ç¬¬1æ­¥ï¼‰ï¼š

```python
# æ—§ä»£ç 
def log(msg: str) -> None:
    print(msg, flush=True)

log(f"[HTTP] attempt {attempt}/{MAX_RETRIES} failed: {e}")

# æ–°ä»£ç 
from src.logger import setup_logger
logger = setup_logger(__name__)

logger.error(
    "HTTP request failed on attempt %d/%d: %s",
    attempt, MAX_RETRIES, e,
    exc_info=True  # è‡ªåŠ¨è®°å½•æ ˆ
)
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] `src/logger.py` åˆ›å»º
- [ ] step6è¿ç§»å®Œæˆ
- [ ] è¿è¡Œstep6ï¼Œæ£€æŸ¥`dr_pipeline.log`ç”Ÿæˆ

---

### Day 3-5ï¼šåˆ›å»ºå…±äº«utilsåº“

**åˆ›å»º `src/common.py`**ï¼š

```python
"""å…±äº«å·¥å…·å‡½æ•°åº“

æ¶ˆé™¤è·¨è„šæœ¬çš„ä»£ç é‡å¤ï¼ˆcanonicalize_nameåœ¨5ä¸ªè„šæœ¬ä¸­é‡å¤ï¼‰
"""
import re
from typing import Optional

STOP_WORDS = {
    "tablet", "tablets", "capsule", "capsules", "injection", "injectable",
    "infusion", "oral", "iv", "intravenous", "sc", "subcutaneous",
    "im", "intramuscular", "po", "qd", "bid", "tid", "qod", "qhs",
    "sustained", "extended", "release", "er", "sr", "xr",
    "solution", "suspension", "gel", "cream", "patch", "spray",
    "drops", "drop", "mg", "g", "mcg", "ug", "iu", "ml"
}

def normalize_basic(x: str) -> str:
    """åŸºç¡€æ ‡å‡†åŒ–ï¼šå°å†™ã€å»æ ‡ç‚¹ã€å»å¤šä½™ç©ºæ ¼"""
    s = str(x).lower().strip()
    s = re.sub(r"[\(\)\[\]\{\},;:/\\]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def canonicalize_name(x: str) -> str:
    """è¯ç‰©åç§°è§„èŒƒåŒ–ï¼šå»å‰‚é‡ã€å»åœç”¨è¯ã€ç»Ÿä¸€å¸Œè…Šå­—æ¯

    Example:
        >>> canonicalize_name("Aspirin 100mg Tablet")
        'aspirin'
        >>> canonicalize_name("Interferon-Î± 2b Injection")
        'interferon alpha 2b'
    """
    s = normalize_basic(x)
    if not s:
        return ""

    # å»å‰‚é‡
    s = re.sub(r"\b\d+(\.\d+)?\s*(mg|g|mcg|ug|iu|ml)\b", " ", s, flags=re.I)
    s = re.sub(r"\b\d+(\.\d+)?\b", " ", s)

    # åˆ†è¯+å»åœç”¨è¯
    toks = [t for t in re.split(r"\s+", s) if t]
    toks = [t for t in toks if t not in STOP_WORDS]

    # ç»Ÿä¸€å¸Œè…Šå­—æ¯
    joined = " ".join(toks).replace("Î±", "alpha").replace("Î²", "beta")
    joined = re.sub(r"\s+", " ", joined).strip()

    return joined

def safe_filename(s: str, max_len: int = 80) -> str:
    """è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å

    Example:
        >>> safe_filename("Drug/Name (100mg)")
        'drug_name_100mg_'
    """
    s = re.sub(r"[^a-zA-Z0-9\-_]+", "_", str(s).strip().lower())
    s = re.sub(r"_+", "_", s).strip("_")
    return s[:max_len] or "drug"

def normalize_pmid(v: Optional[str]) -> str:
    """æå–æ ‡å‡†PMIDï¼ˆ6-9ä½æ•°å­—ï¼‰

    Example:
        >>> normalize_pmid("PMID: 12345678")
        '12345678'
        >>> normalize_pmid("123")
        ''
    """
    if v is None:
        return ""
    s = str(v).strip()
    if not s:
        return ""
    m = re.search(r"\b(\d{6,9})\b", s)
    return m.group(1) if m else ""
```

**é‡æ„è„šæœ¬**ï¼ˆstep5ç¤ºä¾‹ï¼‰ï¼š

```python
# æ—§ä»£ç ï¼ˆstep5å†…éƒ¨å®šä¹‰ï¼‰
def canonicalize_name(x: str) -> str:
    s = normalize_basic(x)
    ...

# æ–°ä»£ç 
from src.common import canonicalize_name, normalize_basic, safe_filename

# ç›´æ¥ä½¿ç”¨ï¼Œåˆ é™¤æœ¬åœ°å®šä¹‰
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] `src/common.py` åˆ›å»º
- [ ] step5/6/7/8è¿ç§»å®Œæˆ
- [ ] åˆ é™¤æœ¬åœ°é‡å¤å®šä¹‰
- [ ] è¿è¡Œstep5-8ï¼Œç¡®è®¤æ— é”™è¯¯

---

### Day 6-7ï¼šå•å…ƒæµ‹è¯•æ¡†æ¶

**åˆ›å»º `tests/test_common.py`**ï¼š

```python
"""å…±äº«å·¥å…·å‡½æ•°å•å…ƒæµ‹è¯•"""
import pytest
from src.common import canonicalize_name, normalize_pmid, safe_filename

class TestCanonicalizeName:
    """æµ‹è¯•è¯ç‰©åç§°è§„èŒƒåŒ–"""

    def test_remove_dosage(self):
        assert canonicalize_name("aspirin 100mg tablet") == "aspirin"
        assert canonicalize_name("Drug 50 ug injection") == "drug"

    def test_greek_letters(self):
        assert canonicalize_name("interferon-Î±") == "interferon alpha"
        assert canonicalize_name("TNF-Î² inhibitor") == "tnf beta inhibitor"

    def test_empty_input(self):
        assert canonicalize_name("") == ""
        assert canonicalize_name("   ") == ""

    @pytest.mark.parametrize("input,expected", [
        ("DRUG (Parenteral)", "drug parenteral"),
        ("Drug  Multiple   Spaces", "drug multiple spaces"),
        ("123 mg only dosage", ""),  # åªæœ‰å‰‚é‡
    ])
    def test_edge_cases(self, input, expected):
        assert canonicalize_name(input) == expected

class TestNormalizePMID:
    """æµ‹è¯•PMIDæ ‡å‡†åŒ–"""

    def test_valid_pmid(self):
        assert normalize_pmid("12345678") == "12345678"
        assert normalize_pmid("PMID: 12345678") == "12345678"
        assert normalize_pmid("Found in PMID 23456789 study") == "23456789"

    def test_invalid_pmid(self):
        assert normalize_pmid("abc") == ""
        assert normalize_pmid("123") == ""  # å¤ªçŸ­
        assert normalize_pmid("1234567890") == ""  # å¤ªé•¿
        assert normalize_pmid(None) == ""

    def test_multiple_pmids(self):
        # è¿”å›ç¬¬ä¸€ä¸ª
        assert normalize_pmid("12345678 and 23456789") == "12345678"

class TestSafeFilename:
    """æµ‹è¯•æ–‡ä»¶åå®‰å…¨åŒ–"""

    def test_special_chars(self):
        assert safe_filename("drug/name") == "drug_name"
        assert safe_filename("drug (100mg)") == "drug_100mg_"

    def test_long_name(self):
        long = "a" * 100
        result = safe_filename(long, max_len=80)
        assert len(result) == 80

    def test_empty(self):
        assert safe_filename("") == "drug"
        assert safe_filename("!!!") == "drug"
```

**è¿è¡Œæµ‹è¯•**ï¼š

```bash
# å®‰è£…pytest
pip install pytest pytest-cov

# è¿è¡Œæµ‹è¯•
pytest tests/test_common.py -v

# è¿è¡Œå¸¦è¦†ç›–ç‡
pytest tests/test_common.py --cov=src.common --cov-report=term-missing
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] pytestå®‰è£…
- [ ] `tests/test_common.py` åˆ›å»º
- [ ] æµ‹è¯•é€šè¿‡ï¼ˆç»¿è‰²ï¼‰
- [ ] è¦†ç›–ç‡ >90%

---

## ğŸ”§ ç¬¬2å‘¨ï¼šé…ç½®ä¸å¼‚å¸¸å¤„ç†

### Day 8-9ï¼šé…ç½®ç®¡ç†

**åˆ›å»º `.env.example`**ï¼š

```bash
# PubMed APIé…ç½®
NCBI_API_KEY=your_ncbi_api_key_here
NCBI_DELAY=0.6
PUBMED_TIMEOUT=30
PUBMED_EFETCH_CHUNK=20

# Ollamaé…ç½®
OLLAMA_HOST=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_LLM_MODEL=qwen2.5:7b-instruct
OLLAMA_TIMEOUT=600

# é‡è¯•ç­–ç•¥
MAX_RETRIES=4
RETRY_SLEEP=2

# åŠŸèƒ½å¼€å…³
DISABLE_EMBED=0
DISABLE_LLM=0
CROSS_DRUG_FILTER=1
FORCE_REBUILD=0
REFRESH_EMPTY_CACHE=1

# Step7ç­–ç•¥å‚æ•°
TOPIC_MIN=0.30
MIN_UNIQUE_PMIDS=2
SAFETY_HARD_NOGO=0

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=dr_pipeline.log
```

**åˆ›å»º `src/config.py`**ï¼š

```python
"""é…ç½®ç®¡ç†æ¨¡å—"""
import os
from dotenv import load_dotenv
import logging

logger = logging.getLogger(__name__)

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

class Config:
    """å…¨å±€é…ç½®ç±»"""

    # PubMedé…ç½®
    NCBI_EUTILS: str = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    NCBI_API_KEY: str = os.getenv("NCBI_API_KEY", "").strip()
    NCBI_DELAY: float = float(os.getenv("NCBI_DELAY", "0.6"))
    PUBMED_TIMEOUT: float = float(os.getenv("PUBMED_TIMEOUT", "30"))
    PUBMED_EFETCH_CHUNK: int = int(os.getenv("PUBMED_EFETCH_CHUNK", "20"))

    # Ollamaé…ç½®
    OLLAMA_HOST: str = os.getenv("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
    OLLAMA_EMBED_MODEL: str = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
    OLLAMA_LLM_MODEL: str = os.getenv("OLLAMA_LLM_MODEL", "qwen2.5:7b-instruct")
    OLLAMA_TIMEOUT: float = float(os.getenv("OLLAMA_TIMEOUT", "600"))

    # é‡è¯•é…ç½®
    MAX_RETRIES: int = int(os.getenv("MAX_RETRIES", "4"))
    RETRY_SLEEP: float = float(os.getenv("RETRY_SLEEP", "2"))

    # åŠŸèƒ½å¼€å…³
    DISABLE_EMBED: bool = os.getenv("DISABLE_EMBED", "0") == "1"
    DISABLE_LLM: bool = os.getenv("DISABLE_LLM", "0") == "1"
    CROSS_DRUG_FILTER: bool = os.getenv("CROSS_DRUG_FILTER", "1") == "1"
    FORCE_REBUILD: bool = os.getenv("FORCE_REBUILD", "0") == "1"
    REFRESH_EMPTY_CACHE: bool = os.getenv("REFRESH_EMPTY_CACHE", "1") == "1"

    @classmethod
    def validate(cls) -> None:
        """éªŒè¯å…³é”®é…ç½®"""
        if cls.NCBI_API_KEY:
            logger.info("NCBI API key configured (length: %d)", len(cls.NCBI_API_KEY))
        else:
            logger.warning("NCBI_API_KEY not set - rate limiting will apply")

        if cls.MAX_RETRIES < 1:
            raise ValueError("MAX_RETRIES must be >= 1")

        if cls.OLLAMA_TIMEOUT < 10:
            logger.warning("OLLAMA_TIMEOUT < 10s may cause failures")

# å¯åŠ¨æ—¶éªŒè¯
Config.validate()
```

**è¿ç§»ç¤ºä¾‹**ï¼ˆstep6ï¼‰ï¼š

```python
# æ—§ä»£ç 
NCBI_API_KEY = os.getenv("NCBI_API_KEY", "").strip()
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "4"))

# æ–°ä»£ç 
from src.config import Config

def pubmed_esearch(term: str, retmax: int = 200) -> List[str]:
    params = {"db": "pubmed", "term": term, ...}
    if Config.NCBI_API_KEY:
        params["api_key"] = Config.NCBI_API_KEY
    ...
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] `.env.example` åˆ›å»º
- [ ] `src/config.py` åˆ›å»º
- [ ] step6è¿ç§»å®Œæˆ
- [ ] å¯åŠ¨æ—¶æ‰“å°é…ç½®éªŒè¯æ—¥å¿—

---

### Day 10-11ï¼šè§„èŒƒåŒ–å¼‚å¸¸å¤„ç†

**é‡æ„ç¤ºä¾‹**ï¼ˆstep6çš„ollama_embedå‡½æ•°ï¼‰ï¼š

```python
# æ—§ä»£ç 
def ollama_embed(texts: List[str], model: str) -> Optional[List[List[float]]]:
    try:
        r = request_with_retries("POST", url, ...)
        data = r.json()
        embs = data.get("embeddings")
        if isinstance(embs, list) and embs:
            return embs
    except Exception:  # âŒ è¿‡äºå®½æ³›
        pass

    try:
        # é™çº§åˆ°æ—§æ¥å£
        ...
    except Exception as e:  # âŒ ä»ç„¶è¿‡äºå®½æ³›
        log(f"[WARN] embedding disabled: {e}")
        return None

# æ–°ä»£ç 
import requests
from requests.exceptions import ConnectionError, Timeout, HTTPError

def ollama_embed(texts: List[str], model: str) -> Optional[List[List[float]]]:
    """è°ƒç”¨Ollama embedding API

    Returns:
        åµŒå…¥å‘é‡åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None

    Raises:
        ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œæ‰€æœ‰é”™è¯¯éƒ½è¢«æ•è·å¹¶è®°å½•
    """
    if Config.DISABLE_EMBED:
        return None

    if not texts:
        return []

    url = f"{Config.OLLAMA_HOST}/api/embed"

    # å°è¯•æ–°æ¥å£
    try:
        r = request_with_retries(
            "POST", url,
            json={"model": model, "input": texts},
            timeout=Config.OLLAMA_TIMEOUT,
            trust_env=False
        )
        data = r.json()
        embs = data.get("embeddings")

        if isinstance(embs, list) and embs and isinstance(embs[0], list):
            return embs

        logger.warning("Unexpected embedding response format: %s", data)

    except (ConnectionError, Timeout) as e:
        logger.error("Ollama connection failed: %s", e, exc_info=True)
        return None

    except HTTPError as e:
        if e.response.status_code == 404:
            logger.info("New API not found, trying fallback endpoint")
        else:
            logger.error("Ollama HTTP error %d: %s", e.response.status_code, e)
            return None

    except ValueError as e:
        logger.error("Invalid JSON response: %s", e)
        return None

    # é™çº§åˆ°æ—§æ¥å£
    try:
        url_old = f"{Config.OLLAMA_HOST}/api/embeddings"
        out = []
        for t in texts:
            r = request_with_retries(
                "POST", url_old,
                json={"model": model, "prompt": t},
                timeout=Config.OLLAMA_TIMEOUT,
                trust_env=False
            )
            data = r.json()
            e = data.get("embedding")
            if not isinstance(e, list):
                raise ValueError(f"Invalid embedding type: {type(e)}")
            out.append(e)
        return out

    except Exception as e:
        logger.error("Fallback embedding also failed: %s", e, exc_info=True)
        return None
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] step6çš„ollama_embedé‡æ„å®Œæˆ
- [ ] å¼‚å¸¸ç±»å‹ç²¾ç¡®åŒ–
- [ ] æ—¥å¿—è®°å½•è¯¦ç»†åŒ–
- [ ] è¿è¡Œstep6ï¼Œæ£€æŸ¥æ—¥å¿—è´¨é‡

---

## ğŸ“Š ç¬¬3å‘¨ï¼šæµ‹è¯•è¦†ç›–æ‰©å±•

### Day 12-14ï¼šæ ¸å¿ƒå‡½æ•°å•å…ƒæµ‹è¯•

**åˆ›å»º `tests/test_step6_retrieval.py`**ï¼š

```python
"""Step6æ£€ç´¢åŠŸèƒ½å•å…ƒæµ‹è¯•"""
import pytest
from unittest.mock import patch, MagicMock
import sys
sys.path.insert(0, 'scripts')

from step6_pubmed_rag_ollama_evidence_v2 import (
    pubmed_esearch,
    bm25_rank,
    classify_endpoint,
    topic_match_ratio
)

class TestPubMedSearch:
    """æµ‹è¯•PubMedæœç´¢"""

    @patch('step6_pubmed_rag_ollama_evidence_v2.request_with_retries')
    def test_esearch_success(self, mock_request):
        """æµ‹è¯•æˆåŠŸæœç´¢"""
        mock_response = MagicMock()
        mock_response.json.return_value = {
            'esearchresult': {'idlist': ['12345678', '23456789']}
        }
        mock_request.return_value = mock_response

        result = pubmed_esearch("aspirin atherosclerosis", retmax=10)
        assert result == ['12345678', '23456789']

    @patch('step6_pubmed_rag_ollama_evidence_v2.request_with_retries')
    def test_esearch_empty(self, mock_request):
        """æµ‹è¯•ç©ºç»“æœ"""
        mock_response = MagicMock()
        mock_response.json.return_value = {'esearchresult': {}}
        mock_request.return_value = mock_response

        result = pubmed_esearch("nonexistent_drug_12345", retmax=10)
        assert result == []

class TestBM25Rank:
    """æµ‹è¯•BM25æ’åº"""

    def test_empty_query(self):
        """ç©ºæŸ¥è¯¢åº”è¿”å›ç©ºåˆ—è¡¨"""
        docs = [{'title': 'Test', 'abstract': 'Abstract'}]
        result = bm25_rank("", docs)
        assert result == []

    def test_empty_docs(self):
        """ç©ºæ–‡æ¡£åº”è¿”å›ç©ºåˆ—è¡¨"""
        result = bm25_rank("query", [])
        assert result == []

    def test_relevance_ranking(self):
        """æµ‹è¯•ç›¸å…³æ€§æ’åº"""
        docs = [
            {'title': 'Aspirin in cardiovascular disease', 'abstract': 'Study on aspirin effects'},
            {'title': 'Diabetes treatment', 'abstract': 'Metformin for diabetes'},
            {'title': 'Aspirin mechanism', 'abstract': 'Aspirin inhibits platelets'}
        ]

        result = bm25_rank("aspirin cardiovascular", docs, topk=3)

        assert len(result) == 3
        # ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯æœ€ç›¸å…³çš„
        assert 'aspirin' in result[0][1]['title'].lower()
        # åˆ†æ•°åº”è¯¥é€’å‡
        assert result[0][0] >= result[1][0] >= result[2][0]

class TestEndpointClassification:
    """æµ‹è¯•ç«¯ç‚¹åˆ†ç±»"""

    def test_plaque_imaging(self):
        assert classify_endpoint("Coronary plaque volume by CTA", "") == "PLAQUE_IMAGING"
        assert classify_endpoint("Carotid intima-media thickness", "") == "PLAQUE_IMAGING"

    def test_pad_function(self):
        assert classify_endpoint("Six-minute walking distance", "") == "PAD_FUNCTION"
        assert classify_endpoint("Treadmill test for claudication", "") == "PAD_FUNCTION"

    def test_cv_events(self):
        assert classify_endpoint("MACE composite endpoint", "") == "CV_EVENTS"
        assert classify_endpoint("Myocardial infarction rate", "") == "CV_EVENTS"

    def test_other(self):
        assert classify_endpoint("Quality of life score", "") == "OTHER"

class TestTopicMatch:
    """æµ‹è¯•ä¸»é¢˜åŒ¹é…"""

    def test_plaque_match(self):
        text = "Atherosclerotic plaque progression measured by IVUS showed significant reduction"
        ratio = topic_match_ratio(text, "PLAQUE_IMAGING")
        assert ratio > 0.2  # åº”æœ‰å¤šä¸ªå…³é”®è¯å‘½ä¸­

    def test_no_match(self):
        text = "This study investigated diabetes in pediatric population"
        ratio = topic_match_ratio(text, "PLAQUE_IMAGING")
        assert ratio < 0.1  # å‡ ä¹æ— å‘½ä¸­
```

**è¿è¡Œæµ‹è¯•**ï¼š

```bash
pytest tests/test_step6_retrieval.py -v --cov=scripts.step6_pubmed_rag_ollama_evidence_v2
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] `tests/test_step6_retrieval.py` åˆ›å»º
- [ ] æµ‹è¯•é€šè¿‡
- [ ] step6å…³é”®å‡½æ•°è¦†ç›–ç‡ >70%

---

### Day 15-17ï¼šé›†æˆæµ‹è¯•+å›å½’æµ‹è¯•

**åˆ›å»º `tests/test_step6_integration.py`**ï¼š

```python
"""Step6é›†æˆæµ‹è¯•"""
import pytest
import pandas as pd
from pathlib import Path
import tempfile
import sys
sys.path.insert(0, 'scripts')

from step6_pubmed_rag_ollama_evidence_v2 import process_one

class TestStep6Integration:
    """Step6ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""

    @pytest.fixture
    def temp_output_dir(self):
        """ä¸´æ—¶è¾“å‡ºç›®å½•"""
        with tempfile.TemporaryDirectory() as tmpdir:
            yield Path(tmpdir)

    @pytest.mark.slow
    @pytest.mark.integration
    def test_process_one_drug(self, temp_output_dir):
        """æµ‹è¯•å¤„ç†å•ä¸ªè¯ç‰©ï¼ˆçœŸå®APIè°ƒç”¨ï¼‰"""
        # ä½¿ç”¨å·²çŸ¥è¯ç‰©ï¼ˆå¦‚aspirinï¼‰
        json_path, md_path, dossier = process_one(
            drug_id="test_001",
            canonical_name="aspirin",
            target_disease="atherosclerosis",
            endpoint_type_hint="CV_EVENTS",
            neg_path=None,
            out_dir=temp_output_dir,
            cache_dir=temp_output_dir / "cache",
            all_drug_names=["aspirin", "metformin"]
        )

        # éªŒè¯è¾“å‡º
        assert json_path.exists()
        assert md_path.exists()

        # éªŒè¯dossierç»“æ„
        assert dossier['drug_id'] == "test_001"
        assert dossier['canonical_name'] == "aspirin"
        assert 'qc' in dossier
        assert 'llm_structured' in dossier
        assert 'pubmed_rag' in dossier

        # éªŒè¯QCæŒ‡æ ‡
        qc = dossier['qc']
        assert 'topic_match_ratio' in qc
        assert 0.0 <= qc['topic_match_ratio'] <= 1.0

        # éªŒè¯è¯æ®æå–
        llm_struct = dossier['llm_structured']
        assert 'confidence' in llm_struct
        assert llm_struct['confidence'] in ['HIGH', 'MED', 'LOW']
```

**è¿è¡Œé›†æˆæµ‹è¯•**ï¼š

```bash
# è·³è¿‡æ…¢é€Ÿæµ‹è¯•ï¼ˆæ—¥å¸¸å¼€å‘ï¼‰
pytest tests/ -v -m "not slow"

# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆæäº¤å‰ï¼‰
pytest tests/ -v
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] å›å½’æµ‹è¯•å»ºç«‹
- [ ] æ€»ä½“è¦†ç›–ç‡ >70%

---

## ğŸ“ˆ ç¬¬4å‘¨ï¼šå¯è§‚æµ‹æ€§å¢å¼º

### Day 18-20ï¼šæ€§èƒ½ç›‘æ§

**åˆ›å»º `src/profiler.py`**ï¼š

```python
"""æ€§èƒ½ç›‘æ§æ¨¡å—"""
import time
import functools
import logging
from typing import Callable, Any
import psutil
import os

logger = logging.getLogger(__name__)

class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics = {}
        self.process = psutil.Process(os.getpid())

    def record_execution(self, func_name: str, duration: float, memory_mb: float):
        """è®°å½•å‡½æ•°æ‰§è¡ŒæŒ‡æ ‡"""
        if func_name not in self.metrics:
            self.metrics[func_name] = {
                'count': 0,
                'total_time': 0.0,
                'max_time': 0.0,
                'avg_memory_mb': 0.0
            }

        m = self.metrics[func_name]
        m['count'] += 1
        m['total_time'] += duration
        m['max_time'] = max(m['max_time'], duration)
        m['avg_memory_mb'] = (m['avg_memory_mb'] * (m['count'] - 1) + memory_mb) / m['count']

    def get_summary(self):
        """è·å–æ€§èƒ½æ‘˜è¦"""
        summary = []
        for func, m in sorted(self.metrics.items(), key=lambda x: x[1]['total_time'], reverse=True):
            summary.append({
                'function': func,
                'calls': m['count'],
                'total_time_s': round(m['total_time'], 2),
                'avg_time_s': round(m['total_time'] / m['count'], 2),
                'max_time_s': round(m['max_time'], 2),
                'avg_memory_mb': round(m['avg_memory_mb'], 2)
            })
        return summary

    def print_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        logger.info("=" * 80)
        logger.info("Performance Summary")
        logger.info("=" * 80)
        for entry in self.get_summary():
            logger.info(
                "%-30s | %4d calls | %8.2fs total | %6.2fs avg | %6.2fs max | %6.2f MB avg",
                entry['function'],
                entry['calls'],
                entry['total_time_s'],
                entry['avg_time_s'],
                entry['max_time_s'],
                entry['avg_memory_mb']
            )

# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨
metrics = PerformanceMetrics()

def profile(func: Callable) -> Callable:
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""

    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        mem_before = metrics.process.memory_info().rss / 1024 / 1024  # MB
        start = time.time()

        try:
            result = func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start
            mem_after = metrics.process.memory_info().rss / 1024 / 1024
            memory_delta = mem_after - mem_before

            metrics.record_execution(
                func.__name__,
                duration,
                memory_delta
            )

            # æ…¢å‡½æ•°æ—¥å¿—
            if duration > 10:
                logger.info(
                    "Function %s took %.2fs (mem delta: %.2f MB)",
                    func.__name__, duration, memory_delta
                )

    return wrapper
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼ˆstep6ï¼‰ï¼š

```python
from src.profiler import profile, metrics

@profile
def process_one(drug_id: str, canonical_name: str, ...) -> Tuple[Path, Path, Dict]:
    """å¤„ç†å•ä¸ªè¯ç‰©"""
    ...

@profile
def pubmed_esearch(term: str, retmax: int = 200) -> List[str]:
    """PubMedæœç´¢"""
    ...

@profile
def bm25_rank(query: str, docs: List[Dict], ...) -> List[Tuple[float, Dict]]:
    """BM25æ’åº"""
    ...

def main():
    ...
    # ç®¡é“ç»“æŸæ—¶æ‰“å°æŠ¥å‘Š
    metrics.print_report()
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] `src/profiler.py` åˆ›å»º
- [ ] å…³é”®å‡½æ•°æ·»åŠ @profileè£…é¥°å™¨
- [ ] è¿è¡Œstep6ï¼ŒæŸ¥çœ‹æ€§èƒ½æŠ¥å‘Š
- [ ] è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

---

### Day 21-22ï¼šæ–‡æ¡£å­—ç¬¦ä¸²è¡¥å……

**ä¼˜å…ˆçº§é¡ºåº**ï¼š
1. å…¬å…±APIå‡½æ•°ï¼ˆè¢«å…¶ä»–è„šæœ¬è°ƒç”¨ï¼‰
2. å¤æ‚ç®—æ³•å‡½æ•°ï¼ˆbm25_rank, evidence_strength_scoreï¼‰
3. å…³é”®ä¸šåŠ¡é€»è¾‘ï¼ˆprocess_one, load_negative_trialsï¼‰

**ç¤ºä¾‹**ï¼š

```python
def load_negative_trials(
    neg_path: Optional[str],
    canonical_name: str
) -> Tuple[str, List[Dict[str, Any]], str]:
    """ä»CT.gov negative CSVåŠ è½½å¤±è´¥ä¸´åºŠè¯•éªŒæ•°æ®

    ä½¿ç”¨token-basedåŒ¹é…ç­–ç•¥ï¼Œé¿å…å› å‰‚å‹/å‰‚é‡å·®å¼‚å¯¼è‡´çš„åŒ¹é…å¤±è´¥ã€‚

    Args:
        neg_path: CT.gov negative CSVè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            CSVåº”åŒ…å«åˆ—ï¼šdrug_raw/drug_name, nctId, conditions, phase,
            primary_outcome_title, primary_outcome_pvalues
        canonical_name: è§„èŒƒåŒ–è¯ç‰©åç§°ï¼ˆç”¨äºåŒ¹é…ï¼‰

    Returns:
        ä¸‰å…ƒç»„ï¼š
        - endpoint_type: ç«¯ç‚¹ç±»å‹ï¼ˆPLAQUE_IMAGING/PAD_FUNCTION/CV_EVENTS/OTHERï¼‰
        - trials: åŒ¹é…åˆ°çš„è¯•éªŒåˆ—è¡¨ï¼ˆæœ€å¤š10æ¡ï¼‰
        - text_block: Markdownæ ¼å¼çš„è¯•éªŒæ‘˜è¦æ–‡æœ¬

    Example:
        >>> endpoint, trials, md = load_negative_trials(
        ...     "data/poolA_negative_drug_level.csv",
        ...     "aspirin"
        ... )
        >>> print(endpoint)
        'CV_EVENTS'
        >>> print(len(trials))
        5

    Notes:
        - åŒ¹é…ç­–ç•¥ï¼šæå–5+å­—ç¬¦çš„tokenï¼Œé¿å…çŸ­è¯è¯¯åŒ¹é…
        - å»é™¤å‰‚å‹æ‹¬å·å†…å®¹ï¼ˆå¦‚ [100mg tablet]ï¼‰
        - ä¼˜å…ˆåŒ¹é…å®Œæ•´è¯ç‰©åï¼Œç„¶ååŒ¹é…ä¸»è¦token
        - è¿”å›çš„trialsæŒ‰CSVåŸå§‹é¡ºåºï¼ˆé€šå¸¸æ˜¯ç›¸å…³æ€§é€’å‡ï¼‰
    """
    ...
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] step6æ ¸å¿ƒå‡½æ•°docstringè¦†ç›– >80%
- [ ] step7æ ¸å¿ƒå‡½æ•°docstringè¦†ç›– >60%
- [ ] ä½¿ç”¨pydocç”ŸæˆHTMLæ–‡æ¡£éªŒè¯

---

## âœ… ç¬¬5-6å‘¨ï¼šç”Ÿäº§åŒ–å‡†å¤‡ï¼ˆå¯é€‰ï¼‰

### Day 23-25ï¼šCI/CDç®¡é“

**åˆ›å»º `.github/workflows/test.yml`**ï¼š

```yaml
name: Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov

    - name: Run tests
      run: |
        pytest tests/ -v --cov=src --cov=scripts --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        fail_ci_if_error: true
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] GitHub Actionsé…ç½®
- [ ] CIæµ‹è¯•é€šè¿‡
- [ ] è¦†ç›–ç‡æŠ¥å‘Šä¸Šä¼ 

---

### Day 26-28ï¼šDockeråŒ–

**åˆ›å»º `Dockerfile`**ï¼š

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶é¡¹ç›®ä»£ç 
COPY src/ ./src/
COPY scripts/ ./scripts/
COPY data/ ./data/

# ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1
ENV LOG_LEVEL=INFO

# é»˜è®¤å‘½ä»¤
CMD ["python", "scripts/step6_pubmed_rag_ollama_evidence_v2.py", "--help"]
```

**åˆ›å»º `docker-compose.yml`**ï¼š

```yaml
version: '3.8'

services:
  dr-pipeline:
    build: .
    volumes:
      - ./data:/app/data
      - ./output:/app/output
      - ./cache:/app/cache
    environment:
      - NCBI_API_KEY=${NCBI_API_KEY}
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  ollama_data:
```

**æ£€æŸ¥ç‚¹**ï¼š
- [ ] Dockeré•œåƒæ„å»ºæˆåŠŸ
- [ ] docker-composeå¯åŠ¨æˆåŠŸ
- [ ] å®¹å™¨å†…è¿è¡Œstep6æˆåŠŸ

---

## ğŸ“‹ æ€»ç»“æ£€æŸ¥æ¸…å•

### é˜¶æ®µ1å®Œæˆæ ‡å‡†ï¼ˆç¬¬1-2å‘¨ï¼‰

- [ ] âœ… æ—¥å¿—ç³»ç»Ÿè¿ç§»ï¼ˆstep6å®Œæˆï¼‰
- [ ] âœ… å…±äº«utilsåº“ï¼ˆsrc/common.pyï¼Œæ¶ˆé™¤é‡å¤ï¼‰
- [ ] âœ… å•å…ƒæµ‹è¯•æ¡†æ¶ï¼ˆpytestï¼Œè¦†ç›–ç‡>70%ï¼‰
- [ ] âœ… é…ç½®ç®¡ç†ï¼ˆsrc/config.pyï¼Œ.env.exampleï¼‰
- [ ] âœ… å¼‚å¸¸å¤„ç†è§„èŒƒåŒ–ï¼ˆç²¾ç¡®å¼‚å¸¸ç±»å‹ï¼‰

**éªŒè¯æ–¹å¼**ï¼š
```bash
# è¿è¡Œæµ‹è¯•
pytest tests/ -v --cov=src --cov-report=term-missing

# é¢„æœŸï¼š
# - æµ‹è¯•é€šè¿‡ >20ä¸ª
# - è¦†ç›–ç‡ >70%
# - æ—¥å¿—æ–‡ä»¶dr_pipeline.logç”Ÿæˆ

# è¿è¡Œstep6
python scripts/step6_pubmed_rag_ollama_evidence_v2.py \
  --rank_in data/step6_rank.csv \
  --out output/step6_test

# é¢„æœŸï¼š
# - æ—¥å¿—æ¸…æ™°åˆ†çº§
# - å¼‚å¸¸è¯¦ç»†è®°å½•
# - æ€§èƒ½æŠ¥å‘Šæ‰“å°
```

---

### é˜¶æ®µ2å®Œæˆæ ‡å‡†ï¼ˆç¬¬3-4å‘¨ï¼‰

- [ ] âœ… æµ‹è¯•è¦†ç›–æ‰©å±•ï¼ˆstep6 >80%ï¼Œstep7 >60%ï¼‰
- [ ] âœ… æ€§èƒ½ç›‘æ§é›†æˆï¼ˆ@profileè£…é¥°å™¨ï¼‰
- [ ] âœ… å‡½æ•°docstringï¼ˆæ ¸å¿ƒå‡½æ•° >80%ï¼‰
- [ ] âœ… é›†æˆæµ‹è¯•å»ºç«‹

**éªŒè¯æ–¹å¼**ï¼š
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v --cov=src --cov=scripts --cov-report=html

# æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š
open htmlcov/index.html

# é¢„æœŸï¼š
# - src/common.pyè¦†ç›–ç‡ >90%
# - step6å…³é”®å‡½æ•°è¦†ç›–ç‡ >80%
# - æ€»ä½“è¦†ç›–ç‡ >70%
```

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | éªŒè¯æ–¹å¼ |
|------|------|------|---------|
| **ä»£ç é‡å¤ç‡** | ~15% | <2% | grep -r "def canonicalize_name" |
| **æµ‹è¯•è¦†ç›–ç‡** | <5% | >70% | pytest --cov |
| **æ—¥å¿—è´¨é‡** | print() | logging | æ£€æŸ¥dr_pipeline.log |
| **é…ç½®ç®¡ç†** | æ•£ä¹± | ç»Ÿä¸€ | æ£€æŸ¥src/config.py |
| **å¼‚å¸¸å¤„ç†** | å®½æ³› | ç²¾ç¡® | ä»£ç å®¡æŸ¥ |
| **æ–‡æ¡£è¦†ç›–** | ~20% | >80% | pydocç”Ÿæˆ |

---

## ğŸ’¡ å¸¸è§é—®é¢˜

**Q: æ”¹è¿›ä¼šç ´åç°æœ‰åŠŸèƒ½å—ï¼Ÿ**
A: ä¸ä¼šã€‚æ‰€æœ‰æ”¹è¿›éƒ½æ˜¯å¢é‡å¼çš„ï¼Œæ¯æ­¥éƒ½æœ‰éªŒè¯ã€‚å•å…ƒæµ‹è¯•ä½œä¸ºå®‰å…¨ç½‘ã€‚

**Q: éœ€è¦å¤šå°‘æ—¶é—´ï¼Ÿ**
A: é˜¶æ®µ1ï¼ˆåŸºç¡€è®¾æ–½ï¼‰ï¼š2-3å‘¨
   é˜¶æ®µ2ï¼ˆå¯è§‚æµ‹æ€§ï¼‰ï¼š1-2å‘¨
   æ€»è®¡ï¼š**6å‘¨**ï¼ˆ1äººå…¨èŒï¼‰

**Q: å¦‚ä½•å¤„ç†ç§‘ç ”deadlineå†²çªï¼Ÿ**
A: ä¼˜å…ˆå®ŒæˆP0ä»»åŠ¡ï¼ˆæ—¥å¿—+å…±äº«åº“+æµ‹è¯•ï¼‰ï¼ŒP1/P2å¯å»¶åã€‚

**Q: æµ‹è¯•è¦†ç›–70%æ˜¯å¦è¿‡é«˜ï¼Ÿ**
A: ä¸é«˜ã€‚è¦†ç›–æ ¸å¿ƒå‡½æ•°ï¼ˆcommon.py, retrieval, QC logicï¼‰ï¼Œè·³è¿‡ç®€å•å·¥å…·å‡½æ•°ã€‚

---

**å¼€å§‹è¡ŒåŠ¨**ï¼šä»Day 1å¼€å§‹ï¼Œæ¯å¤©è¿›æ­¥ä¸€ç‚¹ç‚¹ï¼ğŸš€
