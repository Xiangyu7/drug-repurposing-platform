# LLM+RAGè¯æ®å·¥ç¨‹ å·¥ä¸šçº§æˆç†Ÿåº¦åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¥æœŸ**: 2026-02-07
**é¡¹ç›®**: LLM+RAGè¯æ®å·¥ç¨‹ (åŠ¨è„‰ç²¥æ ·ç¡¬åŒ–è¯ç‰©å†åˆ©ç”¨)
**ä»£ç é‡**: ~5,100 è¡ŒPython
**æ ¸å¿ƒæŠ€æœ¯**: LLM + RAG + PubMed + ClinicalTrials.gov

  1. å¿…è¯»ï¼šQUICK_START_IMPROVEMENTS.mdï¼ˆç¬¬1-2å‘¨éƒ¨åˆ†ï¼‰ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
  2. æ·±å…¥ï¼šINDUSTRIAL_READINESS_REPORT.mdï¼ˆç†è§£è®¾è®¡åŸç†ï¼‰ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
  3. éªŒè¯ï¼šæ¯å‘¨æ£€æŸ¥æ¸…å• ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
---

## æ‰§è¡Œæ‘˜è¦

LLM+RAGè¯æ®å·¥ç¨‹æ˜¯ä¸€ä¸ª**è®¾è®¡ä¼˜ç§€çš„ç§‘ç ”ç®¡é“**ï¼Œä»£ç è´¨é‡**ä¸­ç­‰åä¸Šï¼ˆ3.0/5.0ï¼‰**ã€‚å…·æœ‰å®Œå–„çš„ç±»å‹ç³»ç»Ÿã€æ™ºèƒ½çš„ç¼“å­˜ç­–ç•¥å’Œè‰¯å¥½çš„å‡½æ•°æ¨¡å—åŒ–ã€‚ä½†åœ¨å·¥ä¸šçº§éƒ¨ç½²æ‰€éœ€çš„**æ—¥å¿—ç³»ç»Ÿã€æµ‹è¯•è¦†ç›–ã€é”™è¯¯å¤„ç†ã€ä»£ç å¤ç”¨**ç­‰å…³é”®ç»´åº¦å­˜åœ¨æ˜¾è‘—å·®è·ã€‚

**å½“å‰çŠ¶æ€**: é€‚åˆç ”ç©¶ç¯å¢ƒè¿è¡Œ
**è·ç¦»å·¥ä¸šçº§**: éœ€è¦ **6-8å‘¨çš„å·¥ç¨‹åŒ–é‡æ„**
**å…³é”®ç“¶é¢ˆ**: å¯ç»´æŠ¤æ€§ã€å¯è§‚æµ‹æ€§ã€æµ‹è¯•è¦†ç›–

> **âš ï¸ 2026-02-12 æ›´æ–°**: æœ¬æŠ¥å‘Šå†™äº 2026-02-07ã€‚è‡ªæ­¤ä¹‹åï¼Œä»¥ä¸‹æ”¹è¿›å·²å®Œæˆ:
> - âœ… æµ‹è¯•è¦†ç›–: 0% â†’ **501 tests** (75%+ è¦†ç›–ç‡)
> - âœ… ä»£ç é‡å¤: 15% â†’ **<2%** (å…±äº« `src/dr/` æ¨¡å—)
> - âœ… æ•°æ® Schema: æ—  â†’ **ContractEnforcer** (Step7/8/9 è‡ªåŠ¨æ ¡éªŒ)
> - âœ… æ—¥å¿—ç³»ç»Ÿ: print â†’ **ç»“æ„åŒ– logging** (`src/dr/logger.py`)
> - âœ… é…ç½®ç®¡ç†: æ•£ä¹± â†’ **Config class** (`src/dr/config.py`)
> - âœ… æ–°å¢: Release Gateã€Audit Logã€Human Review Metricsã€Monitoring Alerts
> - âœ… æ–°å¢: Bootstrap CI ä¸ç¡®å®šæ€§é‡åŒ–ã€æ•°æ®æ³„æ¼å®¡è®¡
> - âœ… CI/CD: GitHub Actions monorepo çŸ©é˜µæµ‹è¯•
>
> å½“å‰è¯„åˆ†çº¦ **3.0 â†’ 4.0/5.0**ã€‚è·¯çº¿å›¾ä¸­é˜¶æ®µ 1+2 å·²åŸºæœ¬å®Œæˆã€‚

---

## ä¸€ã€å½“å‰é¡¹ç›®åšå¾—å¥½çš„åœ°æ–¹ âœ…

### 1.1 ç±»å‹ç³»ç»Ÿéå¸¸å®Œå–„ â­â­â­â­â­ (5/5)

**äº®ç‚¹**ï¼š95%ä»¥ä¸Šçš„å‡½æ•°éƒ½æœ‰å®Œæ•´çš„ç±»å‹æç¤º

```python
# ä¼˜ç§€ç¤ºä¾‹ï¼šstep6_pubmed_rag_ollama_evidence_v2.py
def load_negative_trials(
    neg_path: Optional[str],
    canonical_name: str
) -> Tuple[str, List[Dict[str, Any]], str]:
    """Return (endpoint_type, trials, text_block_for_md)."""
    ...

def bm25_rank(
    query: str,
    docs: List[Dict[str, Any]],
    k1: float = 1.5,
    b: float = 0.75,
    topk: int = 80
) -> List[Tuple[float, Dict[str, Any]]]:
    ...
```

**ä¼˜åŠ¿**ï¼š
- ä»£ç å¯è¯»æ€§å¼º
- IDEè‡ªåŠ¨è¡¥å…¨å®Œç¾
- ç±»å‹é”™è¯¯æ˜“äºå‘ç°
- ä¸ºé™æ€æ£€æŸ¥ï¼ˆmypyï¼‰åšå¥½å‡†å¤‡

---

### 1.2 ç¼“å­˜æ¶æ„è®¾è®¡ä¼˜ç§€ â­â­â­â­ (4/5)

**å››å±‚ç¼“å­˜è®¾è®¡**ï¼š

```
cache/pubmed/{drug_id}/{canonical_name}/
  â”œâ”€â”€ pmids.json              # L1: æœç´¢ç»“æœç¼“å­˜
  â”œâ”€â”€ pubmed.xml              # L2: PubMed XMLå“åº”
  â”œâ”€â”€ docs.json               # L3: è§£æåçš„æ–‡æ¡£
  â””â”€â”€ reranked_pmids.json     # L4: æ’åºåçš„PMID
```

**å…³é”®å®ç°**ï¼š

```python
# åŸå­å†™å…¥é˜²æ­¢ç¼“å­˜æŸå
def write_json(path: Path, obj: Any) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(path.suffix + ".tmp")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")
    tmp.replace(path)  # âœ… åŸå­æ“ä½œ

# æ¡ä»¶ç¼“å­˜åˆ·æ–°
if FORCE_REBUILD or is_empty(pmids_path) or (REFRESH_EMPTY_CACHE and is_empty(pmids_path)):
    pmids = pubmed_esearch(query, retmax=200)
    write_json(pmids_path, {"query": query, "pmids": pmids})
else:
    pmids = (read_json(pmids_path) or {}).get("pmids", [])
```

**ä¼˜åŠ¿**ï¼š
- åˆ†å±‚ç¼“å­˜å‡å°‘APIè°ƒç”¨
- åŸå­å†™å…¥ä¿è¯ä¸€è‡´æ€§
- æŒ‰è¯ç‰©éš”ç¦»é˜²æ­¢å†²çª
- å¯é…ç½®å¼ºåˆ¶åˆ·æ–°

---

### 1.3 HTTPé‡è¯•æœºåˆ¶å¥å£® â­â­â­â­ (4/5)

**å®ç°ç»†èŠ‚**ï¼š

```python
def request_with_retries(method: str, url: str, **kwargs) -> requests.Response:
    """Robust HTTP helper with retries."""
    last = None
    timeout_default = kwargs.get("timeout", REQUEST_TIMEOUT)

    for attempt in range(1, MAX_RETRIES + 1):  # âœ… æœ€å¤š4æ¬¡é‡è¯•
        try:
            kw = dict(kwargs)  # âœ… é¿å…æ±¡æŸ“åŸå§‹å‚æ•°
            timeout = kw.pop("timeout", timeout_default)
            trust_env = kw.pop("trust_env", True)

            if trust_env is False:
                sess = requests.Session()
                sess.trust_env = False
                r = sess.request(method, url, timeout=timeout, **kw)
            else:
                r = requests.request(method, url, timeout=timeout, **kw)

            r.raise_for_status()
            return r
        except Exception as e:
            last = e
            log(f"[HTTP] attempt {attempt}/{MAX_RETRIES} failed: {e}")
            time.sleep(RETRY_SLEEP * attempt)  # âœ… æŒ‡æ•°é€€é¿

    raise RuntimeError(f"HTTP failed after {MAX_RETRIES} retries: {last}")
```

**ä¼˜åŠ¿**ï¼š
- æŒ‡æ•°é€€é¿å‡å°‘æœåŠ¡å™¨å‹åŠ›
- å‚æ•°éš”ç¦»é˜²æ­¢é‡è¯•æ±¡æŸ“
- å¯é…ç½®é‡è¯•æ¬¡æ•°/å»¶è¿Ÿ
- å…¼å®¹Ollamaçš„trust_env=Falseæ¨¡å¼

---

### 1.4 æ•°æ®è´¨é‡æ§åˆ¶å®Œå–„ â­â­â­â­ (4/5)

**Step6çš„QCæœºåˆ¶**ï¼š

```python
# ä¸»é¢˜åŒ¹é…ç‡æ£€æµ‹
ev_text_all = " ".join([str(e.get("claim","")) for e in supporting[:8]]) + " " + \
              " ".join([d.get("abstract","")[:500] for d in top_docs[:2]])
tmr_all = topic_match_ratio(ev_text_all, endpoint_type)
mismatch = tmr_all < 0.30 and endpoint_type != "OTHER"

# ç§»é™¤ç¦»é¢˜è¯æ®
if float(ev.get("topic_match_ratio", 0.0)) == 0.0 and endpoint_type != "OTHER":
    removed += 1
    qc_reasons.append("removed_offtopic_supporting")
    harm_or_neutral.append({**ev, "supports": False, "direction": "neutral"})

# è·¨è¯ç‰©æ±¡æŸ“æ£€æµ‹
if CROSS_DRUG_FILTER and contains_other_drug(claim_txt, other_markers):
    pre_qc_reasons.append('cross_drug_leakage')
    pre_removed += 1
    continue
```

**QCè¾“å‡º**ï¼š

```json
{
  "qc": {
    "topic_match_ratio": 0.42,
    "topic_mismatch": false,
    "removed_evidence_count": 3,
    "removed_cross_drug_count": 1,
    "supporting_evidence_after_qc": 7,
    "qc_reasons": ["cross_drug_leakage", "removed_offtopic_supporting"]
  }
}
```

**Step7çš„ç­–ç•¥è·¯ç”±**ï¼š

```python
# ç¡¬è·¯ç”±é€»è¾‘
if topic_ratio < TOPIC_MIN:
    gate_reasons.append(f"topic_ratio<{TOPIC_MIN}")
if se_unique < MIN_UNIQUE_PMIDS:
    gate_reasons.append(f"unique_pmids<{MIN_UNIQUE_PMIDS}")
if SAFETY_HARD_NOGO and safety_hit:
    gate_reasons.append("safety_blacklist_hard")

if gate_reasons:
    gate_decision = "NO_GO"
else:
    gate_decision = "PROCEED_PLAN"
```

**ä¼˜åŠ¿**ï¼š
- ç«¯ç‚¹é©±åŠ¨çš„ä¸»é¢˜æ£€æµ‹
- è·¨è¯ç‰©æ±¡æŸ“è¿‡æ»¤
- å¤šç»´QCåŸå› è¿½è¸ª
- å®‰å…¨é»‘åå•ç¡¬è·¯ç”±

---

### 1.5 é…ç½®ç®¡ç†è®¾è®¡å®Œå–„ï¼ˆStep6ï¼‰ â­â­â­â­ (4/5)

**20+ç¯å¢ƒå˜é‡é…ç½®**ï¼š

```python
# APIé…ç½®
NCBI_EUTILS = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
NCBI_API_KEY = os.getenv("NCBI_API_KEY", "").strip()
NCBI_DELAY = float(os.getenv("NCBI_DELAY", "0.6"))
PUBMED_TIMEOUT = float(os.getenv("PUBMED_TIMEOUT", "30"))
PUBMED_EFETCH_CHUNK = int(os.getenv("PUBMED_EFETCH_CHUNK", "20"))

# Ollamaé…ç½®
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
OLLAMA_EMBED_MODEL = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
OLLAMA_LLM_MODEL = os.getenv("OLLAMA_LLM_MODEL", "qwen2.5:7b-instruct")
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "600"))

# é‡è¯•é…ç½®
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "4"))
RETRY_SLEEP = float(os.getenv("RETRY_SLEEP", "2"))

# åŠŸèƒ½å¼€å…³
DISABLE_EMBED = os.getenv("DISABLE_EMBED", "0") == "1"
DISABLE_LLM = os.getenv("DISABLE_LLM", "0") == "1"
CROSS_DRUG_FILTER = os.getenv("CROSS_DRUG_FILTER", "1") == "1"
FORCE_REBUILD = os.getenv("FORCE_REBUILD", "0") == "1"
REFRESH_EMPTY_CACHE = os.getenv("REFRESH_EMPTY_CACHE", "1") == "1"
```

**ä¼˜åŠ¿**ï¼š
- å®Œå–„çš„ç¯å¢ƒå˜é‡è¦†ç›–
- åˆç†çš„é»˜è®¤å€¼
- å¸ƒå°”å¼€å…³ç»Ÿä¸€è§„èŒƒ
- æ”¯æŒç¦ç”¨Ollamaè¿è¡Œ

---

### 1.6 ç«¯ç‚¹åˆ†å±‚ç­–ç•¥èªæ˜ â­â­â­â­ (4/5)

**ä¸‰å±‚ç«¯ç‚¹åˆ†ç±»**ï¼š

```python
def classify_endpoint(primary_outcome_title: str, conditions: str) -> str:
    s = f"{primary_outcome_title} {conditions}".lower()

    # æ–‘å—æˆåƒï¼ˆé«˜ç²¾åº¦ï¼‰
    if any(k in s for k in ["plaque", "atheroma", "cta", "ivus", "carotid", "intima-media"]):
        return "PLAQUE_IMAGING"

    # PADåŠŸèƒ½ï¼ˆä¸­ç²¾åº¦ï¼‰
    if any(k in s for k in ["six-minute walk", "claudication", "walking distance", "pad"]):
        return "PAD_FUNCTION"

    # å¿ƒè¡€ç®¡äº‹ä»¶ï¼ˆä½ç²¾åº¦ï¼‰
    if any(k in s for k in ["mace", "major adverse", "myocardial infarction", "stroke"]):
        return "CV_EVENTS"

    return "OTHER"
```

**ç«¯ç‚¹é©±åŠ¨çš„æŸ¥è¯¢æ„å»º**ï¼š

```python
ENDPOINT_QUERY = {
    "PLAQUE_IMAGING": '(atherosclerosis OR plaque OR "noncalcified plaque" OR CTA OR IVUS)',
    "PAD_FUNCTION": '("peripheral artery disease" OR PAD OR claudication OR "six-minute walk")',
    "CV_EVENTS": '("myocardial infarction" OR MI OR "acute coronary syndrome" OR MACE)',
    "OTHER": '(atherosclerosis OR cardiovascular OR vascular OR inflammation)'
}

def build_query(drug: str, target_disease: str, endpoint_type: str) -> str:
    endpoint_clause = ENDPOINT_QUERY.get(endpoint_type, ENDPOINT_QUERY["OTHER"])
    if endpoint_type == "OTHER":
        return f'("{drug}") AND ({endpoint_clause}) AND ("{target_disease}")'
    return f'("{drug}") AND ({endpoint_clause})'
```

**ä¼˜åŠ¿**ï¼š
- é¿å…"ä¸€åˆ€åˆ‡"çš„atherosclerosisæŸ¥è¯¢
- åŒ¹é…ä¸´åºŠè¯•éªŒçš„çœŸå®ç«¯ç‚¹
- å‡å°‘ç¦»é¢˜æ–‡çŒ®æ£€ç´¢
- æé«˜ä¸»é¢˜åŒ¹é…ç‡

---

### 1.7 æ¨¡å—çº§æ–‡æ¡£è¯¦ç»† â­â­â­â­ (4/5)

**ç¤ºä¾‹**ï¼š

```python
"""
Step6 (v2): PubMed RAG + Evidence Engineering with:
1) Evidence blocks (not single sentences) with required PMID + direction/model/endpoint fields
2) Endpoint-driven topic gating (plaque/PAD/events) rather than one-size-fits-all "atherosclerosis"
3) Two-stage retrieval: broad PubMed -> BM25 pre-rank -> (optional) Ollama embedding rerank
4) Negative evidence extraction & counting (CT.gov + abstract "no difference"/harm language)

Designed to be drop-in upgrade for pipelines using step6_rank.csv + dossier_json used by step7_build_from_step6.py.

Run (example):
  OLLAMA_HOST=http://localhost:11434 OLLAMA_EMBED_MODEL=nomic-embed-text OLLAMA_LLM_MODEL=qwen2.5:7b-instruct \
  python step6_pubmed_rag_ollama_evidence_v2.py \
    --rank_in step6_rank.csv --neg poolA_negative_drug_level.csv --out step6_v2_out --target_disease atherosclerosis

Outputs:
  - {out}/step6_rank_v2.csv  (updated dossier paths + evidence counts)
  - {out}/dossiers/{drug_id}__{canonical}.json
  - {out}/dossiers/{drug_id}__{canonical}.md
  - {out}/cache/pubmed/... (pmids + xml + parsed docs + embeddings cache)

Notes:
- Requires: requests, pandas, tqdm (and a running Ollama if you want embedding/LLM)
- Network access needed for PubMed E-utilities.
"""
```

**ä¼˜åŠ¿**ï¼š
- æ¸…æ™°çš„è®¾è®¡æ„å›¾
- å®Œæ•´çš„è¿è¡Œç¤ºä¾‹
- è¾“å‡ºæ–‡ä»¶è¯´æ˜
- ä¾èµ–é¡¹åˆ—è¡¨

---

## äºŒã€å…³é”®å·®è·ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰

### ğŸ”´ P0 - é˜»å¡æ€§å·®è·ï¼ˆå¿…é¡»ä¿®å¤æ‰èƒ½ç”Ÿäº§éƒ¨ç½²ï¼‰

#### 2.1 æ—¥å¿—ç³»ç»ŸåŸå§‹ â­â­/5 â†’ ç›®æ ‡ â­â­â­â­â­

**å½“å‰çŠ¶æ€**ï¼š

```python
def log(msg: str) -> None:
    print(msg, flush=True)

# ä½¿ç”¨æ–¹å¼
log(f"[HTTP] attempt {attempt}/{MAX_RETRIES} failed: {e}")
log(f"[WARN] embedding disabled (ollama): {e}")
log(f"[OK] wrote: {out_csv}")
```

**é—®é¢˜**ï¼š
- âŒ æ— æ—¥å¿—çº§åˆ«ï¼ˆDEBUG/INFO/WARNING/ERRORï¼‰
- âŒ æ— æ—¶é—´æˆ³
- âŒ ä¸æŒä¹…åŒ–ï¼ˆstdoutä¸¢å¤±åæ— æ³•è¿½æº¯ï¼‰
- âŒ æ— ç»“æ„åŒ–æ—¥å¿—ï¼ˆéš¾ä»¥è§£æï¼‰
- âŒ æ— æ—¥å¿—è½®æ¢ï¼ˆé•¿æœŸè¿è¡Œä¼šå æ»¡ç£ç›˜ï¼‰
- âŒ æ— è°ƒç”¨æ ˆä¿¡æ¯ï¼ˆéš¾ä»¥å®šä½é—®é¢˜ï¼‰

**å·¥ä¸šçº§è¦æ±‚**ï¼š

```python
import logging
import logging.handlers

# ç»“æ„åŒ–æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(name)s | %(levelname)s | %(funcName)s:%(lineno)d | %(message)s',
    handlers=[
        logging.handlers.RotatingFileHandler(
            'dr_pipeline.log',
            maxBytes=100*1024*1024,  # 100MB
            backupCount=5
        ),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ä½¿ç”¨æ–¹å¼
logger.info("Processing drug: %s", drug_name)
logger.warning("Embedding disabled due to error: %s", exc_info=True)
logger.error("HTTP request failed after %d retries", MAX_RETRIES, extra={
    'url': url,
    'status_code': response.status_code,
    'drug_id': drug_id
})
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… ç”Ÿäº§é—®é¢˜å¯è¿½æº¯
- âœ… æ”¯æŒæ—¥å¿—èšåˆï¼ˆELK/Splunkï¼‰
- âœ… å¯é…ç½®æ—¥å¿—çº§åˆ«
- âœ… å¼‚å¸¸è‡ªåŠ¨è®°å½•æ ˆä¿¡æ¯

---

#### 2.2 æµ‹è¯•è¦†ç›–ä¸¥é‡ä¸è¶³ â­/5 â†’ ç›®æ ‡ â­â­â­â­

**å½“å‰çŠ¶æ€**ï¼š

```
tests/
  â””â”€â”€ test_step6_llm_single.py  (376è¡Œï¼Œå•ä¸€é›†æˆæµ‹è¯•)
```

**é—®é¢˜**ï¼š
- âŒ æ— å•å…ƒæµ‹è¯•æ¡†æ¶ï¼ˆpytestï¼‰
- âŒ æ ¸å¿ƒå‡½æ•°0%è¦†ç›–
- âŒ æ— è¾¹ç•Œæ¡ä»¶æµ‹è¯•
- âŒ æ— å›å½’æµ‹è¯•
- âŒ æ— CIé›†æˆ

**å·¥ä¸šçº§è¦æ±‚**ï¼š

```python
# tests/test_common.py
import pytest
from src.common import canonicalize_name, normalize_pmid

class TestCanonicalizeName:
    def test_remove_dosage(self):
        assert canonicalize_name("aspirin 100mg tablet") == "aspirin"

    def test_greek_letters(self):
        assert canonicalize_name("interferon-Î±") == "interferon alpha"

    def test_empty_input(self):
        assert canonicalize_name("") == ""
        assert canonicalize_name(None) == ""

    @pytest.mark.parametrize("input,expected", [
        ("drug (100mg)", "drug"),
        ("drug 50 ug injection", "drug"),
        ("DRUG  Multiple   Spaces", "drug multiple spaces"),
    ])
    def test_edge_cases(self, input, expected):
        assert canonicalize_name(input) == expected

class TestNormalizePMID:
    def test_valid_pmid(self):
        assert normalize_pmid("12345678") == "12345678"
        assert normalize_pmid("PMID: 12345678") == "12345678"

    def test_invalid_pmid(self):
        assert normalize_pmid("abc") == ""
        assert normalize_pmid("123") == ""  # å¤ªçŸ­
        assert normalize_pmid(None) == ""

# tests/test_step6_retrieval.py
from unittest.mock import patch, MagicMock
from scripts.step6_pubmed_rag_ollama_evidence_v2 import pubmed_esearch, bm25_rank

class TestPubMedRetrieval:
    @patch('requests.request')
    def test_esearch_with_api_key(self, mock_request):
        mock_response = MagicMock()
        mock_response.json.return_value = {
            'esearchresult': {'idlist': ['12345678', '23456789']}
        }
        mock_request.return_value = mock_response

        result = pubmed_esearch("aspirin atherosclerosis", retmax=10)
        assert result == ['12345678', '23456789']
        assert mock_request.call_args[1]['params']['api_key'] is not None

    def test_bm25_rank_empty_query(self):
        docs = [{'title': 'Test', 'abstract': 'Test abstract'}]
        result = bm25_rank("", docs)
        assert result == []

    def test_bm25_rank_relevance(self):
        docs = [
            {'title': 'Aspirin in cardiovascular disease', 'abstract': 'Study on aspirin'},
            {'title': 'Diabetes treatment', 'abstract': 'Metformin study'}
        ]
        result = bm25_rank("aspirin cardiovascular", docs, topk=2)
        assert len(result) == 2
        assert result[0][1]['title'] == 'Aspirin in cardiovascular disease'
```

**æµ‹è¯•è¦†ç›–ç›®æ ‡**ï¼š

| æ¨¡å— | å½“å‰è¦†ç›– | ç›®æ ‡è¦†ç›– |
|------|---------|---------|
| common.py | 0% | >90% |
| step6 retrieval | 0% | >80% |
| step6 QC logic | 0% | >75% |
| step7 gating | 0% | >70% |
| **æ€»ä½“** | <5% | **>70%** |

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… é‡æ„æ—¶ä¸æ€•ç ´ååŠŸèƒ½
- âœ… è¾¹ç•Œæ¡ä»¶è¦†ç›–
- âœ… å›å½’æµ‹è¯•è‡ªåŠ¨åŒ–
- âœ… CI/CDå¯é›†æˆ

---

#### 2.3 ä»£ç é‡å¤ä¸¥é‡ â­â­/5 â†’ ç›®æ ‡ â­â­â­â­â­

**é—®é¢˜**ï¼š

```python
# åœ¨5ä¸ªè„šæœ¬ä¸­é‡å¤å®šä¹‰ï¼š
# - step5_drug_normalize_and_aggregate_v3.py
# - step7_build_from_step6.py
# - step7_build_from_step6_v2.py
# - step8_fusion_rank.py

def canonicalize_name(x: str) -> str:
    s = normalize_basic(x)
    if not s:
        return ""
    s = re.sub(r"\b\d+(\.\d+)?\s*(mg|g|mcg|ug|iu|ml)\b", " ", s, flags=re.I)
    s = re.sub(r"\b\d+(\.\d+)?\b", " ", s)
    toks = [t for t in re.split(r"\s+", s) if t]
    toks = [t for t in toks if t not in STOP_WORDS]
    joined = " ".join(toks).replace("Î±","alpha").replace("Î²","beta")
    joined = re.sub(r"\s+", " ", joined).strip()
    return joined

# ç±»ä¼¼çš„è¿˜æœ‰ï¼š
# - normalize_basic() - 5æ¬¡é‡å¤
# - safe_filename() - 4æ¬¡é‡å¤
# - STOP_WORDSå¸¸é‡ - 5æ¬¡é‡å¤
```

**å·¥ä¸šçº§è¦æ±‚**ï¼š

```
DR/
â”œâ”€â”€ src/                     # â­ æ–°å¢ï¼šå…±äº«åº“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ common.py            # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ logger.py            # æ—¥å¿—é…ç½®
â”‚   â”œâ”€â”€ validators.py        # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ constants.py         # å¸¸é‡å®šä¹‰
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ step6_pubmed_rag_ollama_evidence_v2.py
â”‚   â””â”€â”€ ...
â””â”€â”€ tests/
    â”œâ”€â”€ test_common.py
    â””â”€â”€ ...
```

**src/common.py**ï¼š

```python
"""å…±äº«å·¥å…·å‡½æ•°åº“"""
import re
from typing import Optional

STOP_WORDS = {
    "tablet", "tablets", "capsule", "capsules", "injection", "injectable",
    "oral", "iv", "intravenous", "sc", "subcutaneous", "mg", "g", "mcg"
}

def normalize_basic(x: str) -> str:
    """åŸºç¡€æ ‡å‡†åŒ–ï¼šå°å†™ã€å»æ ‡ç‚¹ã€å»å¤šä½™ç©ºæ ¼"""
    s = str(x).lower().strip()
    s = re.sub(r"[\(\)\[\]\{\},;:/\\]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def canonicalize_name(x: str) -> str:
    """è¯ç‰©åç§°è§„èŒƒåŒ–ï¼šå»å‰‚é‡ã€å»åœç”¨è¯ã€ç»Ÿä¸€å¸Œè…Šå­—æ¯"""
    s = normalize_basic(x)
    if not s:
        return ""
    s = re.sub(r"\b\d+(\.\d+)?\s*(mg|g|mcg|ug|iu|ml)\b", " ", s, flags=re.I)
    s = re.sub(r"\b\d+(\.\d+)?\b", " ", s)
    toks = [t for t in re.split(r"\s+", s) if t]
    toks = [t for t in toks if t not in STOP_WORDS]
    joined = " ".join(toks).replace("Î±", "alpha").replace("Î²", "beta")
    joined = re.sub(r"\s+", " ", joined).strip()
    return joined

def safe_filename(s: str, max_len: int = 80) -> str:
    """è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å"""
    s = re.sub(r"[^a-zA-Z0-9\-_]+", "_", str(s).strip().lower())
    s = re.sub(r"_+", "_", s).strip("_")
    return s[:max_len] or "drug"

def normalize_pmid(v: Optional[str]) -> str:
    """æå–æ ‡å‡†PMIDï¼ˆ6-9ä½æ•°å­—ï¼‰"""
    if v is None:
        return ""
    s = str(v).strip()
    if not s:
        return ""
    m = re.search(r"\b(\d{6,9})\b", s)
    return m.group(1) if m else ""
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… DRYåŸåˆ™
- âœ… å•ä¸€çœŸç›¸æº
- âœ… ç»Ÿä¸€æµ‹è¯•
- âœ… ç»´æŠ¤æˆæœ¬é™ä½80%

---

### ğŸŸ  P1 - é«˜ä¼˜å…ˆçº§ï¼ˆå½±å“å¯ç»´æŠ¤æ€§ï¼‰

#### 2.4 å¼‚å¸¸å¤„ç†è¿‡äºå®½æ³› â­â­/5 â†’ ç›®æ ‡ â­â­â­â­

**é—®é¢˜**ï¼š

```python
# Step6 ç¬¬301-316è¡Œ
try:
    r = request_with_retries("POST", url, json={"model": model, "input": texts}, ...)
    data = r.json()
    embs = data.get("embeddings")
    if isinstance(embs, list) and embs and isinstance(embs[0], list):
        return embs
except Exception:  # âŒ æ•è·æ‰€æœ‰å¼‚å¸¸
    pass  # âŒ æ— æ—¥å¿—

# å†æ¬¡å°è¯•æ—§æ¥å£
try:
    url2 = f"{OLLAMA_HOST}/api/embeddings"
    for t in texts:
        r = request_with_retries("POST", url2, json={"model": model, "prompt": t}, ...)
        ...
except Exception as e:  # âŒ ä»ç„¶è¿‡äºå®½æ³›
    log(f"[WARN] embedding disabled (ollama): {e}")
    return None
```

**å·¥ä¸šçº§è¦æ±‚**ï¼š

```python
import requests
from requests.exceptions import ConnectionError, Timeout, HTTPError

def ollama_embed(texts: List[str], model: str) -> Optional[List[List[float]]]:
    if DISABLE_EMBED:
        return None

    if not texts:
        return []

    url = f"{OLLAMA_HOST}/api/embed"

    try:
        r = request_with_retries(
            "POST", url,
            json={"model": model, "input": texts},
            timeout=OLLAMA_TIMEOUT,
            trust_env=False
        )
        data = r.json()
        embs = data.get("embeddings")

        if isinstance(embs, list) and embs and isinstance(embs[0], list):
            return embs

        logger.warning("Unexpected embedding response format: %s", data)

    except (ConnectionError, Timeout) as e:
        logger.error("Ollama connection failed: %s", e, exc_info=True)
        return None

    except HTTPError as e:
        if e.response.status_code == 404:
            logger.info("Trying fallback embedding endpoint (old Ollama API)")
        else:
            logger.error("Ollama HTTP error %d: %s", e.response.status_code, e)
            return None

    except ValueError as e:
        logger.error("Invalid JSON response from Ollama: %s", e)
        return None

    # é™çº§åˆ°æ—§æ¥å£
    try:
        url2 = f"{OLLAMA_HOST}/api/embeddings"
        out = []
        for t in texts:
            r = request_with_retries("POST", url2, json={"model": model, "prompt": t}, ...)
            data = r.json()
            e = data.get("embedding")
            if not isinstance(e, list):
                raise ValueError(f"Invalid embedding format: {type(e)}")
            out.append(e)
        return out

    except Exception as e:
        logger.error("Fallback embedding also failed: %s", e, exc_info=True)
        return None
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… ç²¾ç¡®å¼‚å¸¸ç±»å‹æ•è·
- âœ… è¯¦ç»†æ—¥å¿—è®°å½•
- âœ… åŒºåˆ†å¯æ¢å¤/ä¸å¯æ¢å¤é”™è¯¯
- âœ… å¼‚å¸¸æ ˆè‡ªåŠ¨è®°å½•

---

#### 2.5 ç¼ºä¹é…ç½®æ–‡ä»¶æ ‡å‡† â­â­â­/5 â†’ ç›®æ ‡ â­â­â­â­â­

**å½“å‰é—®é¢˜**ï¼š
- Step6ç¯å¢ƒå˜é‡é…ç½®å®Œå–„
- Step7éƒ¨åˆ†ç¯å¢ƒå˜é‡ç¡¬ç¼–ç 
- æ— .env.exampleæ–‡ä»¶
- æ— é…ç½®éªŒè¯æœºåˆ¶

**å·¥ä¸šçº§è¦æ±‚**ï¼š

**.env.example**ï¼š

```bash
# PubMed APIé…ç½®
NCBI_API_KEY=your_ncbi_api_key_here
NCBI_DELAY=0.6
PUBMED_TIMEOUT=30
PUBMED_EFETCH_CHUNK=20

# Ollamaé…ç½®
OLLAMA_HOST=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text
OLLAMA_LLM_MODEL=qwen2.5:7b-instruct
OLLAMA_TIMEOUT=600

# é‡è¯•ç­–ç•¥
MAX_RETRIES=4
RETRY_SLEEP=2

# åŠŸèƒ½å¼€å…³
DISABLE_EMBED=0
DISABLE_LLM=0
CROSS_DRUG_FILTER=1
FORCE_REBUILD=0
REFRESH_EMPTY_CACHE=1

# Step7ç­–ç•¥å‚æ•°
TOPIC_MIN=0.30
MIN_UNIQUE_PMIDS=2
SAFETY_HARD_NOGO=0

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=dr_pipeline.log
LOG_MAX_BYTES=104857600  # 100MB
LOG_BACKUP_COUNT=5
```

**src/config.py**ï¼š

```python
"""é…ç½®ç®¡ç†æ¨¡å—"""
import os
from typing import Any, Dict
from dotenv import load_dotenv
import logging

logger = logging.getLogger(__name__)

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

class Config:
    """å…¨å±€é…ç½®ç±»"""

    # PubMedé…ç½®
    NCBI_EUTILS: str = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils"
    NCBI_API_KEY: str = os.getenv("NCBI_API_KEY", "").strip()
    NCBI_DELAY: float = float(os.getenv("NCBI_DELAY", "0.6"))
    PUBMED_TIMEOUT: float = float(os.getenv("PUBMED_TIMEOUT", "30"))

    # Ollamaé…ç½®
    OLLAMA_HOST: str = os.getenv("OLLAMA_HOST", "http://localhost:11434").rstrip("/")
    OLLAMA_EMBED_MODEL: str = os.getenv("OLLAMA_EMBED_MODEL", "nomic-embed-text")
    OLLAMA_LLM_MODEL: str = os.getenv("OLLAMA_LLM_MODEL", "qwen2.5:7b-instruct")
    OLLAMA_TIMEOUT: float = float(os.getenv("OLLAMA_TIMEOUT", "600"))

    # é‡è¯•é…ç½®
    MAX_RETRIES: int = int(os.getenv("MAX_RETRIES", "4"))
    RETRY_SLEEP: float = float(os.getenv("RETRY_SLEEP", "2"))

    # åŠŸèƒ½å¼€å…³
    DISABLE_EMBED: bool = os.getenv("DISABLE_EMBED", "0") == "1"
    DISABLE_LLM: bool = os.getenv("DISABLE_LLM", "0") == "1"
    CROSS_DRUG_FILTER: bool = os.getenv("CROSS_DRUG_FILTER", "1") == "1"
    FORCE_REBUILD: bool = os.getenv("FORCE_REBUILD", "0") == "1"

    @classmethod
    def validate(cls) -> None:
        """éªŒè¯å…³é”®é…ç½®"""
        if cls.NCBI_API_KEY:
            logger.info("NCBI API key configured (length: %d)", len(cls.NCBI_API_KEY))
        else:
            logger.warning("NCBI_API_KEY not set - rate limiting will apply")

        if cls.MAX_RETRIES < 1:
            raise ValueError("MAX_RETRIES must be >= 1")

        if cls.OLLAMA_TIMEOUT < 10:
            logger.warning("OLLAMA_TIMEOUT < 10s may cause failures")

        # éªŒè¯Ollamaè¿æ¥ï¼ˆå¯é€‰ï¼‰
        if not cls.DISABLE_EMBED and not cls.DISABLE_LLM:
            try:
                import requests
                r = requests.get(f"{cls.OLLAMA_HOST}/api/tags", timeout=5)
                r.raise_for_status()
                logger.info("Ollama connection verified: %s", cls.OLLAMA_HOST)
            except Exception as e:
                logger.error("Ollama connection failed: %s", e)

    @classmethod
    def to_dict(cls) -> Dict[str, Any]:
        """å¯¼å‡ºé…ç½®ä¸ºå­—å…¸"""
        return {
            k: v for k, v in cls.__dict__.items()
            if not k.startswith('_') and not callable(v)
        }

# å¯åŠ¨æ—¶éªŒè¯
Config.validate()
```

**ä½¿ç”¨æ–¹å¼**ï¼š

```python
# åœ¨è„šæœ¬ä¸­
from src.config import Config

def pubmed_esearch(term: str, retmax: int = 200) -> List[str]:
    params = {
        "db": "pubmed",
        "term": term,
        "retmode": "json",
        "retmax": str(retmax)
    }
    if Config.NCBI_API_KEY:
        params["api_key"] = Config.NCBI_API_KEY

    url = f"{Config.NCBI_EUTILS}/esearch.fcgi"
    r = request_with_retries("GET", url, params=params, timeout=Config.PUBMED_TIMEOUT)
    ...
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… é…ç½®é›†ä¸­ç®¡ç†
- âœ… å¯åŠ¨æ—¶éªŒè¯
- âœ… æ˜“äºæµ‹è¯•ï¼ˆmock Configï¼‰
- âœ… æ–‡æ¡£åŒ–é…ç½®é¡¹

---

#### 2.6 å‡½æ•°çº§æ–‡æ¡£ä¸è¶³ â­â­/5 â†’ ç›®æ ‡ â­â­â­â­

**å½“å‰è¦†ç›–ç‡**ï¼š

| è„šæœ¬ | å‡½æ•°æ•° | æœ‰docstring | è¦†ç›–ç‡ |
|------|--------|------------|-------|
| Step6 | 35 | 12 | 34% |
| Step7 | 15 | 2 | 13% |
| Step8 | 9 | 0 | 0% |
| **å¹³å‡** | - | - | **<20%** |

**ç¼ºé™·ç¤ºä¾‹**ï¼š

```python
def bm25_rank(query: str, docs: List[Dict[str, Any]], k1: float = 1.5, b: float = 0.75, topk: int = 80) -> List[Tuple[float, Dict[str, Any]]]:
    # âŒ æ— docstring
    q = tokenize(query)
    if not q or not docs:
        return []
    ...
```

**å·¥ä¸šçº§è¦æ±‚**ï¼š

```python
def bm25_rank(
    query: str,
    docs: List[Dict[str, Any]],
    k1: float = 1.5,
    b: float = 0.75,
    topk: int = 80
) -> List[Tuple[float, Dict[str, Any]]]:
    """ä½¿ç”¨BM25ç®—æ³•å¯¹æ–‡æ¡£è¿›è¡Œæ’åºã€‚

    BM25æ˜¯ä¸€ç§åŸºäºæ¦‚ç‡æ£€ç´¢æ¨¡å‹çš„æ’åºå‡½æ•°ï¼Œç»¼åˆè€ƒè™‘è¯é¢‘(TF)å’Œé€†æ–‡æ¡£é¢‘ç‡(IDF)ã€‚

    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œä¼šè¢«tokenizeåè®¡ç®—ä¸æ–‡æ¡£çš„ç›¸å…³æ€§
        docs: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å«'title'å’Œ'abstract'å­—æ®µ
        k1: BM25çš„k1å‚æ•°ï¼Œæ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼ˆé»˜è®¤1.5ï¼‰
            - k1è¶Šå¤§ï¼Œé«˜é¢‘è¯çš„å½±å“è¶Šå¤§
            - å…¸å‹èŒƒå›´ï¼š1.2-2.0
        b: BM25çš„bå‚æ•°ï¼Œæ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–ï¼ˆé»˜è®¤0.75ï¼‰
            - b=0æ—¶ä¸è€ƒè™‘æ–‡æ¡£é•¿åº¦
            - b=1æ—¶å®Œå…¨å½’ä¸€åŒ–åˆ°å¹³å‡é•¿åº¦
        topk: è¿”å›å‰Kä¸ªæœ€ç›¸å…³æ–‡æ¡£ï¼ˆé»˜è®¤80ï¼‰

    Returns:
        æ’åºåçš„(åˆ†æ•°, æ–‡æ¡£)å…ƒç»„åˆ—è¡¨ï¼ŒæŒ‰åˆ†æ•°é™åºæ’åˆ—
        åˆ†æ•°è¶Šé«˜è¡¨ç¤ºç›¸å…³æ€§è¶Šå¼º

    Example:
        >>> docs = [
        ...     {'title': 'Aspirin in CVD', 'abstract': 'Study on aspirin...'},
        ...     {'title': 'Diabetes', 'abstract': 'Metformin study...'}
        ... ]
        >>> ranked = bm25_rank("aspirin cardiovascular", docs, topk=10)
        >>> print(ranked[0][1]['title'])
        'Aspirin in CVD'

    Notes:
        - ä½¿ç”¨ç®€å•çš„ç©ºæ ¼+å­—æ¯æ•°å­—tokenization
        - ä¸ä½¿ç”¨å¤–éƒ¨ä¾èµ–ï¼ˆå¦‚rank-bm25åº“ï¼‰ä»¥ä¿æŒè½»é‡
        - IDFè®¡ç®—ä½¿ç”¨å¹³æ»‘å…¬å¼ï¼šlog(1 + (N - df + 0.5) / (df + 0.5))
    """
    q = tokenize(query)
    if not q or not docs:
        return []

    # æ„å»ºè¯­æ–™åº“ç»Ÿè®¡
    doc_toks = [tokenize((d.get("title","") + " " + d.get("abstract","")).strip()) for d in docs]
    N = len(doc_toks)
    avgdl = sum(len(x) for x in doc_toks) / max(1, N)

    # æ–‡æ¡£é¢‘ç‡ï¼ˆdfï¼‰
    df = {}
    for toks in doc_toks:
        for t in set(toks):
            df[t] = df.get(t, 0) + 1

    # IDFè®¡ç®—ï¼ˆå¸¦å¹³æ»‘ï¼‰
    def idf(t: str) -> float:
        n = df.get(t, 0)
        return math.log(1 + (N - n + 0.5) / (n + 0.5))

    # å¯¹æ¯ä¸ªæ–‡æ¡£è®¡ç®—BM25åˆ†æ•°
    ranked = []
    for d, toks in zip(docs, doc_toks):
        dl = len(toks)
        tf = {}
        for t in toks:
            tf[t] = tf.get(t, 0) + 1

        score = 0.0
        for t in q:
            if t not in tf:
                continue
            f = tf[t]
            score += idf(t) * (f * (k1 + 1)) / (f + k1 * (1 - b + b * dl / (avgdl + 1e-9)))

        ranked.append((score, d))

    ranked.sort(key=lambda x: x[0], reverse=True)
    return ranked[:topk]
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… æ–°äººå¿«é€Ÿä¸Šæ‰‹
- âœ… APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆï¼ˆSphinxï¼‰
- âœ… å‡å°‘ä»£ç ç†è§£æˆæœ¬
- âœ… ç®—æ³•ç»†èŠ‚å¯è¿½æº¯

---

### ğŸŸ¡ P2 - ä¸­ä¼˜å…ˆçº§ï¼ˆæ”¹å–„å¯è§‚æµ‹æ€§ï¼‰

#### 2.7 ç¼ºä¹æ€§èƒ½ç›‘æ§ â­â­â­/5 â†’ ç›®æ ‡ â­â­â­â­

**å½“å‰çŠ¶æ€**ï¼š
- æœ‰æŒ‡æ ‡æ”¶é›†ï¼ˆæ”¯æŒè¯æ®æ•°ã€ä¸»é¢˜åŒ¹é…ç‡ç­‰ï¼‰
- æ— æ‰§è¡Œæ—¶é—´è¿½è¸ª
- æ— å†…å­˜ä½¿ç”¨ç›‘æ§
- æ— ç“¶é¢ˆåˆ†æå·¥å…·

**å·¥ä¸šçº§è¦æ±‚**ï¼š

**src/profiler.py**ï¼š

```python
"""æ€§èƒ½ç›‘æ§æ¨¡å—"""
import time
import functools
import logging
from typing import Callable, Any
import psutil
import os

logger = logging.getLogger(__name__)

class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics = {}
        self.process = psutil.Process(os.getpid())

    def record_execution(self, func_name: str, duration: float, memory_mb: float):
        """è®°å½•å‡½æ•°æ‰§è¡ŒæŒ‡æ ‡"""
        if func_name not in self.metrics:
            self.metrics[func_name] = {
                'count': 0,
                'total_time': 0.0,
                'max_time': 0.0,
                'avg_memory_mb': 0.0
            }

        m = self.metrics[func_name]
        m['count'] += 1
        m['total_time'] += duration
        m['max_time'] = max(m['max_time'], duration)
        m['avg_memory_mb'] = (m['avg_memory_mb'] * (m['count'] - 1) + memory_mb) / m['count']

    def get_summary(self):
        """è·å–æ€§èƒ½æ‘˜è¦"""
        summary = []
        for func, m in sorted(self.metrics.items(), key=lambda x: x[1]['total_time'], reverse=True):
            summary.append({
                'function': func,
                'calls': m['count'],
                'total_time_s': round(m['total_time'], 2),
                'avg_time_s': round(m['total_time'] / m['count'], 2),
                'max_time_s': round(m['max_time'], 2),
                'avg_memory_mb': round(m['avg_memory_mb'], 2)
            })
        return summary

# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨
metrics = PerformanceMetrics()

def profile(func: Callable) -> Callable:
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""

    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        mem_before = metrics.process.memory_info().rss / 1024 / 1024  # MB
        start = time.time()

        try:
            result = func(*args, **kwargs)
            return result
        finally:
            duration = time.time() - start
            mem_after = metrics.process.memory_info().rss / 1024 / 1024
            memory_delta = mem_after - mem_before

            metrics.record_execution(
                func.__name__,
                duration,
                memory_delta
            )

            if duration > 10:  # æ…¢å‡½æ•°æ—¥å¿—
                logger.info(
                    "Function %s took %.2fs (mem delta: %.2f MB)",
                    func.__name__, duration, memory_delta
                )

    return wrapper
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
from src.profiler import profile, metrics

@profile
def process_one(drug_id: str, canonical_name: str, ...) -> Tuple[Path, Path, Dict]:
    """å¤„ç†å•ä¸ªè¯ç‰©å€™é€‰"""
    ...

@profile
def pubmed_esearch(term: str, retmax: int = 200) -> List[str]:
    """PubMedæœç´¢"""
    ...

@profile
def bm25_rank(query: str, docs: List[Dict], ...) -> List[Tuple[float, Dict]]:
    """BM25æ’åº"""
    ...

# ç®¡é“ç»“æŸæ—¶æ‰“å°æ€§èƒ½æŠ¥å‘Š
def main():
    ...
    # å¤„ç†å®Œæˆ

    logger.info("=== Performance Summary ===")
    for entry in metrics.get_summary():
        logger.info(
            "%s: %d calls, %.2fs total, %.2fs avg, %.2fs max, %.2f MB avg mem",
            entry['function'],
            entry['calls'],
            entry['total_time_s'],
            entry['avg_time_s'],
            entry['max_time_s'],
            entry['avg_memory_mb']
        )
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
=== Performance Summary ===
process_one: 50 calls, 1234.56s total, 24.69s avg, 45.23s max, 125.34 MB avg mem
pubmed_esearch: 50 calls, 234.12s total, 4.68s avg, 12.34s max, 2.45 MB avg mem
bm25_rank: 50 calls, 45.67s total, 0.91s avg, 2.34s max, 15.23 MB avg mem
ollama_embed: 120 calls, 567.89s total, 4.73s avg, 15.67s max, 8.12 MB avg mem
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
- âœ… å†…å­˜æ³„æ¼æ£€æµ‹
- âœ… ä¼˜åŒ–æŒ‡å¯¼æ•°æ®
- âœ… å®¹é‡è§„åˆ’ä¾æ®

---

#### 2.8 ç¼ºä¹æ•°æ®Schemaå®šä¹‰ â­â­/5 â†’ ç›®æ ‡ â­â­â­â­

**å½“å‰é—®é¢˜**ï¼š
- Stepé—´é€šè¿‡CSVä¼ é€’æ•°æ®
- æ— åˆ—åschemaéªŒè¯
- å­—æ®µå˜æ›´å¯¼è‡´éšå¼é”™è¯¯

**ç¤ºä¾‹é—®é¢˜**ï¼š

```python
# Step6è¾“å‡ºCSVåˆ—å
out_rank["dossier_json"] = dossier_json_paths
out_rank["llm_confidence"] = llm_conf
out_rank["supporting_evidence_count"] = se_cnts
out_rank["unique_supporting_pmids_count"] = se_unique_pmids_cnts

# Step7è¯»å–æ—¶å‡è®¾åˆ—åå­˜åœ¨
if "unique_supporting_pmids_count" in rank.columns:
    se_unique = int(rr.get("unique_supporting_pmids_count", 0) or 0)
else:
    # é™çº§é€»è¾‘
    ...
```

**å·¥ä¸šçº§è¦æ±‚**ï¼š

**src/schemas.py**ï¼š

```python
"""æ•°æ®Schemaå®šä¹‰"""
from typing import Optional, List
from pydantic import BaseModel, Field, validator

class Step6OutputRow(BaseModel):
    """Step6è¾“å‡ºCSVè¡Œschema"""
    drug_id: str = Field(..., description="è¯ç‰©å”¯ä¸€ID")
    canonical_name: str = Field(..., description="è§„èŒƒåŒ–è¯ç‰©åç§°")
    dossier_json: str = Field(..., description="Dossier JSONæ–‡ä»¶è·¯å¾„")
    dossier_md: str = Field(..., description="Dossier MDæ–‡ä»¶è·¯å¾„")
    llm_confidence: str = Field(..., pattern="^(HIGH|MED|LOW)$", description="LLMç½®ä¿¡åº¦")
    pubmed_total_articles: int = Field(ge=0, description="PubMedæ–‡ç« æ€»æ•°")
    rag_top_sentences: int = Field(ge=0, description="RAGé¡¶éƒ¨å¥å­æ•°")
    endpoint_type: str = Field(..., description="ç«¯ç‚¹ç±»å‹")
    supporting_evidence_count: int = Field(ge=0, description="æ”¯æŒè¯æ®æ•°")
    supporting_sentence_count: int = Field(ge=0, description="æ”¯æŒå¥å­æ•°")
    unique_supporting_pmids_count: int = Field(ge=0, description="å”¯ä¸€PMIDæ•°")
    harm_or_neutral_count: int = Field(ge=0, description="ä¸­æ€§/æœ‰å®³è¯æ®æ•°")
    topic_match_ratio: float = Field(ge=0.0, le=1.0, description="ä¸»é¢˜åŒ¹é…ç‡")

    @validator('llm_confidence')
    def validate_confidence(cls, v):
        if v not in {'HIGH', 'MED', 'LOW'}:
            raise ValueError(f'Invalid confidence: {v}')
        return v

class DossierQC(BaseModel):
    """Dossier QCå­—æ®µschema"""
    topic_match_ratio: float = Field(ge=0.0, le=1.0)
    topic_mismatch: bool
    removed_evidence_count: int = Field(ge=0)
    removed_cross_drug_count: int = Field(ge=0)
    supporting_evidence_after_qc: int = Field(ge=0)
    supporting_sentence_count_after_qc: int = Field(ge=0)
    qc_reasons: List[str] = Field(default_factory=list)

class EvidenceItem(BaseModel):
    """è¯æ®é¡¹schema"""
    pmid: str
    supports: bool
    direction: str = Field(..., pattern="^(benefit|harm|neutral|unknown)$")
    model: str = Field(..., pattern="^(human|animal|cell|unknown)$")
    endpoint: str
    claim: str
    confidence: float = Field(ge=0.0, le=1.0)
    source: Optional[str] = Field(None, pattern="^(llm|rule)$")
    topic_match_ratio: Optional[float] = Field(None, ge=0.0, le=1.0)

class Dossier(BaseModel):
    """å®Œæ•´Dossier schema"""
    drug_id: str
    canonical_name: str
    target_disease: str
    endpoint_type: str
    query: str
    qc: DossierQC
    clinicaltrials_negative: List[dict]
    pubmed_rag: dict
    llm_structured: dict
```

**ä½¿ç”¨æ–¹å¼**ï¼š

```python
import pandas as pd
from pydantic import ValidationError
from src.schemas import Step6OutputRow, Dossier

def validate_step6_output(df: pd.DataFrame) -> None:
    """éªŒè¯Step6è¾“å‡ºCSV"""
    for idx, row in df.iterrows():
        try:
            Step6OutputRow(**row.to_dict())
        except ValidationError as e:
            logger.error("Row %d validation failed: %s", idx, e)
            raise

def load_dossier(path: Path) -> Dossier:
    """åŠ è½½å¹¶éªŒè¯Dossier JSON"""
    data = json.loads(path.read_text())
    try:
        return Dossier(**data)
    except ValidationError as e:
        logger.error("Dossier %s validation failed: %s", path, e)
        raise

# åœ¨Step7ä¸­ä½¿ç”¨
rank = pd.read_csv(args.rank_in)
validate_step6_output(rank)  # âœ… æ—©æœŸå‘ç°schemaä¸åŒ¹é…
```

**æ”¹è¿›æ”¶ç›Š**ï¼š
- âœ… æ•°æ®å¥‘çº¦æ˜ç¡®
- âœ… è¿è¡Œæ—¶éªŒè¯
- âœ… IDEè‡ªåŠ¨è¡¥å…¨
- âœ… é‡æ„å®‰å…¨

---

## ä¸‰ã€æ”¹è¿›è·¯çº¿å›¾ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### é˜¶æ®µ1ï¼šåŸºç¡€è®¾æ–½ï¼ˆ2-3å‘¨ï¼‰âš¡ é«˜ä¼˜å…ˆçº§

**ç›®æ ‡**ï¼šå»ºç«‹å·¥ä¸šçº§åŸºç¡€è®¾æ–½

| ä»»åŠ¡ | å·¥ä½œé‡ | å…³é”®äº§å‡º | é˜»å¡é£é™© |
|------|-------|---------|---------|
| âœ… 1.1 æ·»åŠ æ ‡å‡†loggingæ¨¡å— | 3å¤© | `src/logger.py`ï¼Œæ‰€æœ‰è„šæœ¬è¿ç§» | P0 |
| âœ… 1.2 åˆ›å»ºå…±äº«utilsåº“ | 4å¤© | `src/common.py`ï¼Œæ¶ˆé™¤5ä»½é‡å¤ | P0 |
| âœ… 1.3 å¢åŠ å•å…ƒæµ‹è¯•æ¡†æ¶ | 5å¤© | `tests/`ï¼Œpytesté…ç½®ï¼Œæ ¸å¿ƒå‡½æ•°>70%è¦†ç›– | P0 |
| âœ… 1.4 è§„èŒƒåŒ–å¼‚å¸¸å¤„ç† | 3å¤© | ç²¾ç¡®å¼‚å¸¸ç±»å‹ï¼Œè¯¦ç»†æ—¥å¿— | P0 |
| âœ… 1.5 åˆ›å»º.env.example | 1å¤© | é…ç½®æ–‡æ¡£åŒ– | P1 |
| âœ… 1.6 é…ç½®ç®¡ç†æ¨¡å— | 2å¤© | `src/config.py`ï¼Œå¯åŠ¨éªŒè¯ | P1 |

**é‡Œç¨‹ç¢‘1**ï¼šä»£ç è´¨é‡ä»3.0æå‡è‡³3.5

---

### é˜¶æ®µ2ï¼šå¯è§‚æµ‹æ€§ï¼ˆ1-2å‘¨ï¼‰âš™ï¸ ä¸­ä¼˜å…ˆçº§

**ç›®æ ‡**ï¼šå¢å¼ºç›‘æ§å’Œè°ƒè¯•èƒ½åŠ›

| ä»»åŠ¡ | å·¥ä½œé‡ | å…³é”®äº§å‡º | é˜»å¡é£é™© |
|------|-------|---------|---------|
| âœ… 2.1 æ€§èƒ½ç›‘æ§ | 3å¤© | `src/profiler.py`ï¼Œè£…é¥°å™¨ | P2 |
| âœ… 2.2 æ•°æ®Schemaå®šä¹‰ | 3å¤© | `src/schemas.py`ï¼ŒPydanticéªŒè¯ | P2 |
| âœ… 2.3 æ·»åŠ å‡½æ•°docstring | 4å¤© | æ ¸å¿ƒå‡½æ•°>80%è¦†ç›– | P1 |
| âœ… 2.4 é›†æˆmypyç±»å‹æ£€æŸ¥ | 2å¤© | `setup.cfg`ï¼ŒCIé›†æˆ | P2 |

**é‡Œç¨‹ç¢‘2**ï¼šä»£ç è´¨é‡ä»3.5æå‡è‡³4.0

---

### é˜¶æ®µ3ï¼šç”Ÿäº§åŒ–ï¼ˆ2-3å‘¨ï¼‰ğŸš€ å¯é€‰ä½†æ¨è

**ç›®æ ‡**ï¼šæ”¯æŒç”Ÿäº§éƒ¨ç½²

| ä»»åŠ¡ | å·¥ä½œé‡ | å…³é”®äº§å‡º | é˜»å¡é£é™© |
|------|-------|---------|---------|
| âœ… 3.1 CI/CDç®¡é“ | 3å¤© | GitHub Actionsï¼Œè‡ªåŠ¨æµ‹è¯• | P2 |
| âœ… 3.2 DockeråŒ– | 2å¤© | `Dockerfile`ï¼Œ`docker-compose.yml` | P2 |
| âœ… 3.3 æ–­è·¯å™¨æ¨¡å¼ | 3å¤© | APIå¤±è´¥é™çº§ | P2 |
| âœ… 3.4 APIé€Ÿç‡é™åˆ¶é˜Ÿåˆ— | 2å¤© | åŠ¨æ€throttling | P3 |
| âœ… 3.5 æŒ‡æ ‡ä»ªè¡¨æ¿ | 4å¤© | Grafana/Prometheusé›†æˆ | P3 |
| âœ… 3.6 åˆ†å¸ƒå¼è¿½è¸ª | 3å¤© | OpenTelemetry | P3 |

**é‡Œç¨‹ç¢‘3**ï¼šä»£ç è´¨é‡ä»4.0æå‡è‡³4.5ï¼ˆå·¥ä¸šçº§ï¼‰

---

### é˜¶æ®µ4ï¼šé«˜çº§ä¼˜åŒ–ï¼ˆé•¿æœŸï¼‰ğŸ”¬ å¯é€‰

**ç›®æ ‡**ï¼šè¾¾åˆ°æœ€ä½³å®è·µ

| ä»»åŠ¡ | å·¥ä½œé‡ | å…³é”®äº§å‡º |
|------|-------|---------|
| âœ… 4.1 å¼‚æ­¥I/Oï¼ˆasyncioï¼‰ | 5å¤© | å¹¶å‘PubMedè¯·æ±‚ |
| âœ… 4.2 ç¼“å­˜é¢„çƒ­è„šæœ¬ | 2å¤© | æ‰¹é‡é¢„åŠ è½½ |
| âœ… 4.3 A/Bæµ‹è¯•æ¡†æ¶ | 4å¤© | ç®—æ³•å¯¹æ¯” |
| âœ… 4.4 è‡ªåŠ¨åŒ–å›å½’æµ‹è¯• | 3å¤© | Golden dataset |
| âœ… 4.5 APIæ–‡æ¡£ç”Ÿæˆ | 2å¤© | Sphinx |

---

## å››ã€æŠ•å…¥äº§å‡ºåˆ†æ

### 4.1 å·¥ä½œé‡ä¼°ç®—

| é˜¶æ®µ | å·¥ä½œé‡ | äººå‘˜ | æ—¶é—´ |
|------|-------|------|------|
| é˜¶æ®µ1ï¼ˆåŸºç¡€è®¾æ–½ï¼‰ | 18å¤© | 1äºº | 3-4å‘¨ |
| é˜¶æ®µ2ï¼ˆå¯è§‚æµ‹æ€§ï¼‰ | 12å¤© | 1äºº | 2-3å‘¨ |
| é˜¶æ®µ3ï¼ˆç”Ÿäº§åŒ–ï¼‰ | 17å¤© | 1äºº | 3-4å‘¨ |
| **æ€»è®¡ï¼ˆæœ€å°ç”Ÿäº§å°±ç»ªï¼‰** | **30å¤©** | **1äºº** | **6-8å‘¨** |
| é˜¶æ®µ4ï¼ˆé«˜çº§ä¼˜åŒ–ï¼‰ | 16å¤© | 1äºº | 3å‘¨ |

### 4.2 æ”¶ç›Šé‡åŒ–

| ç»´åº¦ | å½“å‰çŠ¶æ€ | æ”¹è¿›å | æå‡ |
|------|---------|-------|------|
| **ä»£ç é‡å¤ç‡** | ~15% | <2% | **87%å‡å°‘** |
| **æµ‹è¯•è¦†ç›–** | <5% | >70% | **14å€** |
| **è°ƒè¯•æ—¶é—´** | 2-4å°æ—¶/bug | 0.5-1å°æ—¶ | **75%å‡å°‘** |
| **æ–°äººä¸Šæ‰‹** | 3-5å¤© | 1å¤© | **70%å‡å°‘** |
| **ç”Ÿäº§äº‹æ•…å“åº”** | æ— æ³•è¿½è¸ª | <15åˆ†é’Ÿ | **100%å¯è§‚æµ‹** |
| **é‡æ„ä¿¡å¿ƒ** | ä½ï¼ˆæ€•ç ´åï¼‰ | é«˜ï¼ˆæµ‹è¯•ä¿æŠ¤ï¼‰ | **è´¨çš„é£è·ƒ** |

### 4.3 ROIåˆ†æ

**æŠ•å…¥**ï¼š1äºº Ã— 6å‘¨ = 240å°æ—¶

**å›æŠ¥**ï¼ˆå¹´åŒ–ï¼‰ï¼š
- å‡å°‘è°ƒè¯•æ—¶é—´ï¼š50 bugs/å¹´ Ã— 2.5å°æ—¶èŠ‚çœ = **125å°æ—¶/å¹´**
- å‡å°‘ä»£ç é‡å¤ç»´æŠ¤ï¼š5æ¬¡é‡å¤ Ã— 20å°æ—¶ = **100å°æ—¶/å¹´**
- å‡å°‘ç”Ÿäº§äº‹æ•…ï¼š3äº‹æ•…/å¹´ Ã— 10å°æ—¶ = **30å°æ—¶/å¹´**
- æ–°äººåŸ¹è®­æˆæœ¬é™ä½ï¼š2äºº/å¹´ Ã— 16å°æ—¶ = **32å°æ—¶/å¹´**

**æ€»å›æŠ¥**ï¼š**287å°æ—¶/å¹´**

**ROI**ï¼š(287 - 240) / 240 = **19.6%** é¦–å¹´æ­£æ”¶ç›Šï¼Œ**119.6%** æ¬¡å¹´æ”¶ç›Š

---

## äº”ã€é£é™©ä¸ç¼“è§£

### 5.1 æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| é‡æ„ç ´åç°æœ‰åŠŸèƒ½ | é«˜ | ä¸­ | å…ˆå†™æµ‹è¯•ï¼Œå¢é‡é‡æ„ |
| æµ‹è¯•è¦†ç›–æˆæœ¬è¶…é¢„æœŸ | ä¸­ | é«˜ | ä¼˜å…ˆæ ¸å¿ƒå‡½æ•°ï¼Œé€æ­¥æ‰©å±• |
| æ–°ä¾èµ–å¼•å…¥å†²çª | ä¸­ | ä½ | ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œç‰ˆæœ¬é”å®š |
| æ€§èƒ½ç›‘æ§å¼€é”€ | ä½ | ä¸­ | å¯é€‰è£…é¥°å™¨ï¼Œç”Ÿäº§ç¯å¢ƒé‡‡æ · |

### 5.2 ç»„ç»‡é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| ç§‘ç ”deadlineå†²çª | é«˜ | é«˜ | åˆ†é˜¶æ®µï¼Œå…ˆP0åP2 |
| å›¢é˜ŸæŠµè§¦å·¥ç¨‹åŒ– | ä¸­ | ä¸­ | æ¼”ç¤ºæ”¶ç›Šï¼Œæ¸è¿›å¼æ”¹è¿› |
| ç¼ºä¹å·¥ç¨‹ç»éªŒ | ä¸­ | ä¸­ | å‚è€ƒæœ¬æŠ¥å‘Šï¼Œå¯»æ±‚å’¨è¯¢ |

---

## å…­ã€æ¨èè¡ŒåŠ¨è®¡åˆ’

### ç«‹å³è¡ŒåŠ¨ï¼ˆæœ¬å‘¨ï¼‰

1. âœ… **å¤åˆ¶æœ¬æŠ¥å‘Šç»™å›¢é˜Ÿ**ï¼Œå¯¹é½æ”¹è¿›ç›®æ ‡
2. âœ… **åˆ›å»ºGitHub issueè·Ÿè¸ª**ï¼šä¸ºæ¯ä¸ªP0ä»»åŠ¡åˆ›å»ºissue
3. âœ… **å»ºç«‹.env.example**ï¼š5åˆ†é’Ÿå¿«é€Ÿèƒœåˆ©
4. âœ… **å¯åŠ¨loggingè¿ç§»**ï¼šé€‰æ‹©1ä¸ªè„šæœ¬è¯•ç‚¹ï¼ˆæ¨èstep6ï¼‰

### ç¬¬1-2å‘¨

1. âœ… å®Œæˆ**å…±äº«utilsåº“**ï¼ˆæ¶ˆé™¤é‡å¤ï¼‰
2. âœ… ä¸º**æ ¸å¿ƒå‡½æ•°æ·»åŠ å•å…ƒæµ‹è¯•**ï¼ˆcanonicalize_name, bm25_rank, load_negative_trialsï¼‰
3. âœ… **è§„èŒƒåŒ–å¼‚å¸¸å¤„ç†**ï¼ˆstep6çš„HTTPéƒ¨åˆ†ï¼‰
4. âœ… **æ·»åŠ é…ç½®ç®¡ç†æ¨¡å—**

### ç¬¬3-4å‘¨

1. âœ… **å…¨è„šæœ¬loggingè¿ç§»**
2. âœ… **æµ‹è¯•è¦†ç›–æå‡è‡³50%**
3. âœ… **æ€§èƒ½ç›‘æ§é›†æˆ**
4. âœ… **æ·»åŠ å‡½æ•°docstring**ï¼ˆä¼˜å…ˆå…¬å…±APIï¼‰

### ç¬¬5-6å‘¨

1. âœ… **æ•°æ®Schemaå®šä¹‰**
2. âœ… **CI/CDç®¡é“**ï¼ˆå¯é€‰ï¼‰
3. âœ… **DockeråŒ–**ï¼ˆå¯é€‰ï¼‰
4. âœ… **ç¬¬ä¸€æ¬¡ç”Ÿäº§éƒ¨ç½²æ¼”ç»ƒ**

---

## ä¸ƒã€ç»“è®º

LLM+RAGè¯æ®å·¥ç¨‹å…·æœ‰**åšå®çš„ç§‘ç ”åŸºç¡€**å’Œ**ä¼˜ç§€çš„ç®—æ³•è®¾è®¡**ï¼Œå½“å‰ä»£ç è´¨é‡**ä¸­ç­‰åä¸Šï¼ˆ3.0/5.0ï¼‰**ã€‚é€šè¿‡**6-8å‘¨çš„ç³»ç»Ÿå·¥ç¨‹åŒ–æ”¹è¿›**ï¼Œå¯è¾¾åˆ°**å·¥ä¸šçº§æ ‡å‡†ï¼ˆ4.0/5.0ï¼‰**ï¼Œæ˜¾è‘—æå‡å¯ç»´æŠ¤æ€§ã€å¯è§‚æµ‹æ€§å’Œç”Ÿäº§ç¨³å®šæ€§ã€‚

### å…³é”®è¦ç‚¹

âœ… **åšå¾—å¥½çš„**ï¼šç±»å‹ç³»ç»Ÿã€ç¼“å­˜æ¶æ„ã€QCæœºåˆ¶ã€HTTPé‡è¯•
âŒ **å…³é”®å·®è·**ï¼šæ—¥å¿—ç³»ç»Ÿã€æµ‹è¯•è¦†ç›–ã€ä»£ç é‡å¤ã€å¼‚å¸¸å¤„ç†
âš¡ **ä¼˜å…ˆè¡ŒåŠ¨**ï¼šlogging + å…±äº«åº“ + å•å…ƒæµ‹è¯•ï¼ˆP0ï¼‰
ğŸ“ˆ **é¢„æœŸROI**ï¼šé¦–å¹´19.6%ï¼Œæ¬¡å¹´119.6%

### æœ€ç»ˆå»ºè®®

**é‡‡çº³é˜¶æ®µ1+2ï¼ˆåŸºç¡€è®¾æ–½+å¯è§‚æµ‹æ€§ï¼‰**ï¼ŒæŠ•å…¥**30å¤©**ï¼Œå³å¯å°†ä»£ç è´¨é‡ä»**3.0æå‡è‡³4.0**ï¼Œæ»¡è¶³ç”Ÿäº§éƒ¨ç½²éœ€æ±‚ã€‚é˜¶æ®µ3+4ä¸ºå¯é€‰å¢å¼ºï¼Œå¯æ ¹æ®å®é™…éœ€æ±‚å’Œèµ„æºé€æ­¥æ¨è¿›ã€‚

---

**æŠ¥å‘Šç”Ÿæˆ**: Claude Code (Sonnet 4.5)
**åˆ†ææ·±åº¦**: Very Thorough
**ä»£ç å®¡æŸ¥è¡Œæ•°**: 5,100+ lines
**å‚è€ƒå·¥ä¸šæ ‡å‡†**: Google Python Style Guide, The Twelve-Factor App, SRE Best Practices
